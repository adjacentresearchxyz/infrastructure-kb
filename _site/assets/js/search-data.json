{"0": {
    "doc": "Technical Knowledge Blogs",
    "title": "Technical Knowledge Blogs",
    "content": "Article . URL . Type . Categories . Date . Trends and Inventory of 50 as code concepts . https://www.jedi.be/blog/2022/02/23/trends-and-inventory-of-50-as-code-concepts . engineering . as-code, automation, devops . ########## . Nixos on Apple Silicon  . https://krisztianfekete.org/nixos-on-apple-silicon-with-utm/ . engineering . mac, nixos . ########## . Devops is a Failure . https://leebriggs.co.uk/blog/2022/06/21/devops-is-a-failure . engineering . automation, devops . ########## . Portable Services on Nixos . https://gist.github.com/gdamjan/9f3e4a4016459d3e12f576ec0813c785 . engineering . nixos, systemd . ########## . Re-nixing my os . https://benw.is/posts/renixing-my-os . engineering . nixos . ########## . Understanding #[Derive(Clone)] in Rust . https://stegosaurusdormant.com/understanding-derive-clone/ . engineering . rust . ########## . Crimes with Go Generics . https://xeiaso.net/blog/gonads-2022-04-24 . engineering . go . ########## . Do I need Kubernetes . https://xeiaso.net/blog/do-i-need-kubernetes . engineering . kubernetes . ########## . Nix Flakes: An Introduction . https://xeiaso.net/blog/nix-flakes-1-2022-02-21 . engineering . nix . ########## . Legal Justification of the Backdoor Roth IRA . https://milkyeggs.com/?p=51 . finance . ira . ########## . https://lantian.pub/en/article/modify-website/nixos-why.lantian . https://lantian.pub/en/article/modify-website/nixos-why.lantian/ . engineering . nix . ########## . https://lantian.pub/en/article/modify-website/nixos-initial-config-flake-deploy.lantian . https://lantian.pub/en/article/modify-website/nixos-initial-config-flake-deploy.lantian/ . engineering . nix . ########## . NixOS Series 3: Software Packaging 101 . https://lantian.pub/en/article/modify-computer/nixos-packaging.lantian/ . engineering . nix . ########## . Dotfiles are meant to be forked . https://zachholman.com/2010/08/dotfiles-are-meant-to-be-forked/ . engineering . dotfiles . ########## . https://www.vandorp.biz/2017/02/nixos-linux-vs-coreos-container-linux/ . https://www.vandorp.biz/2017/02/nixos-linux-vs-coreos-container-linux/ . engineering . coreos, nixos . ########## . https://www.domenkozar.com/2014/03/11/why-puppet-chef-ansible-arent-good-enough-and-we-can-do-better . https://www.domenkozar.com/2014/03/11/why-puppet-chef-ansible-arent-good-enough-and-we-can-do-better/ . engineering . automation . ########## . Recommended Terraform Workflow . https://developer.hashicorp.com/terraform/cloud-docs/recommended-practices/part1 . engineering . terraform . ########## . Managing Multiple Environments in Terraform . https://blog.gruntwork.io/how-to-manage-multiple-environments-with-terraform-32c7bc5d692 . engineering . terraform . ########## . Terraform and NixOS . https://github.com/tweag/terraform-nixos . engineering . nixos, terraform . ########## . Tailscale vs. Boundry . https://tailscale.com/compare/hashicorp-boundary/ . engineering . hashiorp, tailscale, vpn . ########## . MagicDNS . https://tailscale.com/blog/2021-09-private-dns-with-magicdns/ . engineering . DNS, tailscale . ########## . Google StyleGuide . https://google.github.io/styleguide/ . engineering . style . ########## . Notes on Funding Rates and Perpetual Markets with Niche Price Feeds . https://oips.overlay.market/notes . crypto, finance . defi, perpetuals . ########## . The EVM Handbook . https://noxx3xxon.notion.site/The-EVM-Handbook-bb38e175cc404111a391907c4975426d . engineering . evm . ########## . Stake^2 How to Cheat the Staking Mechanism in Solana . https://blog.neodyme.io/posts/solana_core_2/ . engineering . hacks, solana . ########## . Consul at Fly.io . https://fly.io/blog/a-foolish-consistency/ . engineering . consul, devops . ########## . An Introduction to Nix Shell . http://ghedam.at/15978/an-introduction-to-nix-shell . engineering . nix . ########## . Algorithmic Trading in Crypto . https://medium.com/galois-capital/algorithmic-trading-in-crypto-430431da1e0a . finance . trading . ########## . The only crypto story you need . https://www.bloomberg.com/features/2022-the-crypto-story/?leadSource=uverify%20wall . finance . crypto . ########## . Creating a Nix Package . https://elatov.github.io/2022/01/building-a-nix-package/#building-with-nix . engineering . nix . ########## . How to Setup Prometheus, Grafana and Loki on NixOS . https://xeiaso.net/blog/prometheus-grafana-loki-nixos-2020-11-20 . engineering . grafana, nix . ########## . Visualizing with Grafana . https://clickhouse.com/blog/visualizing-data-with-grafana . engineering . grafana . ########## . Chips and China . https://stratechery.com/2022/chips-and-china/ . finance . china, chips, manufacturing . ########## . Moontower Money Wiki . https://notion.moontowermeta.com/moontower-money-wiki . finance . options, risk managment, trading . ########## . Since the merge how are things changing?  . https://pintail.xyz/posts/since-the-merge/ . crypto, finance . crypto, ethereum, merge . ########## . Things Hidden since the foundation of blockspace . https://www.aniccaresearch.tech/blog/things-hidden-since-foundation-of-blockspace . crypto, finance . blockspace, crypto . ########## . The Sovereign Stack . https://odyslam.com/blog/sovereign-stack/ . crypto, finance . crypto, decentralization . ########## . Why running a trading desk is hard . https://www.smbtraining.com/blog/running-a-trading-desk-why-its-so-hard . finance . trading . ########## . Deploy Infrastructure with CDK and Golan . https://michaellin.me/deploy-infrastructure-using-cdktf-with-go/ . engineering . golang, terraform . ########## . FTX Tangled Ties with Celsius . https://dirtybubblemedia.substack.com/p/ftxed-the-tangled-ties-of-celsius . finance . ftx . ########## . Molecular Notes: Principles . https://reasonabledeviations.com/2022/04/18/molecular-notes-part-1/ . productivity . knowledge base . ########## . Hypothesis Testing in quant finance . https://reasonabledeviations.com/2021/06/17/hypothesis-testing-quant/ . productivity . quant . ########## . How I use Notion . https://reasonabledeviations.com/2021/09/18/how-i-use-notion/ . productivity . knowledge base . ########## . Molecular Notes: Practice . https://reasonabledeviations.com/2022/06/12/molecular-notes-part-2/ . productivity . knowledge base . ########## . Option implied probability distributions: Pt 2 . https://reasonabledeviations.com/2020/10/10/option-implied-pdfs-2/ . finance . options . ########## . Option implied probability distributions: Pt 1 . https://reasonabledeviations.com/2020/10/01/option-implied-pdfs/ . finance . options . ########## . Equity Investing Checklist . https://reasonabledeviations.com/2020/08/20/investing-checklist/ . finance . equity . ########## . A Tanker Trade . https://reasonabledeviations.com/2020/04/24/oil-storage/ . finance . investing . ########## . A asymmetric bet on interest rates . https://reasonabledeviations.com/2019/12/05/asymmetric-bet-interest-rates/ . finance . investing . ########## . How predictive is the historical volatility . https://reasonabledeviations.com/2019/11/01/how-predictive-is-historical-volatility/ . finance . investing . ########## . What we learnt building an enterprise blockchain startup . https://reasonabledeviations.com/2019/09/01/what-we-learnt-enterprise-blockchain/ . engineering, finance . blockchain, startup . ########## . Graph algorithms and currency arbitrage: Pt 1 . https://reasonabledeviations.com/2019/03/02/currency-arbitrage-graphs/ . engineering, finance . arbitrage, crypto . ########## . Graph algorithms and currency arbitrage: Pt 2 . https://reasonabledeviations.com/2019/04/21/currency-arbitrage-graphs-2/ . engineering, finance . arbitrage, crypto . ########## . Five ways to build a $100 million business . http://christophjanz.blogspot.com/2014/10/five-ways-to-build-100-million-business.html . finance . startups . ########## . Extreme Edge . https://open.substack.com/pub/twoquants/p/extreme-edge . finance . arbitrage, trading . ########## . Office chairs are a scam . https://scottlocklin.wordpress.com/2021/04/23/office-chairs-are-a-scam/ . lifestyle . opinon . ########## . How market making works Pt. 2 . https://idrawcharts.medium.com/market-making-article-2-not-illustrated-but-much-more-in-depth-25f1257656ac . finance . market making . ########## . How market making works . https://idrawcharts.medium.com/how-market-making-works-poorly-illustrated-128b5ae8304d . finance . market making . ########## . Bitcoin is not a store of value . https://cryptostackers.substack.com/p/bitcoin-is-not-a-store-of-value . finance . crypto, opinon . ########## . Bitcoin and economic nihilism . https://xeiaso.net/blog/cryptocurrency-ownership . finance . crypto, opinon . ########## . Nix flakes how to package and use them . https://xeiaso.net/blog/nix-flakes-2-2022-02-27 . engineering . nix . ########## . Paranoid Nixos Setup . https://xeiaso.net/blog/paranoid-nixos-2021-07-18 . engineering . nixos . ########## . My Nixos Desktop Flow . https://xeiaso.net/blog/nixos-desktop-flow-2020-04-25 . engineering . nixos . ########## . Tailscale on Nixos . https://tailscale.com/blog/nixos-minecraft/ . engineering . nixos, tailscale . ########## . MEV Market Structure  . https://www.recvc.com/mev-2-0-the-rise-of-mpsvs/ . finance . mev . ########## . Upshot Peer Prediction Whitepaper . https://upshot.xyz/whitepaper.pdf . engineering . prediction, whitepaper . ########## . Where metal is buried . https://amirz.substack.com/p/where-the-metal-is-buried . finance . bitcoin, blockspace, gold . ########## . Consensus Capital Markets . https://www.aniccaresearch.tech/blog/consensus-capital-markets . finance . bitcoin, blockspace . ########## . Introducing Alkmiyia . https://www.aniccaresearch.tech/blog/introducing-alkimiya-protocol . finance . bitcoin, blockspace . ########## . The Intelligent Bitcoin Miner Pt 2 . https://www.aniccaresearch.tech/blog/the-intelligent-bitcoin-miner-pt-ii . finance . bitcoin, blockspace . ########## . The Intelligent Bitcoin Miner Pt 1 . https://www.aniccaresearch.tech/blog/consensus-capital-markets . finance . bitcoin, blockspace . ########## . Ethereum blockspace who gets what and why . https://www.aniccaresearch.tech/blog/ethereum-blockspace-who-gets-what-and-why . finance . bitcoin, blockspace . ########## . Bitcoin Production Cost . https://medium.com/capriole/bitcoins-production-cost-88d889462ea7 . finance . bitcoin, blockspace . ########## . The alchemy of hash power Pt 1 . https://www.aniccaresearch.tech/blog/the-alchemy-of-hashpower-part-i . finance . bitcoin, blockspace . ########## . The alchemy of hashpower Pt 2 . https://www.aniccaresearch.tech/blog/the-alchemy-of-hashpower-part-ii . finance . bitcoin, blockspace . ########## . Bitcoin Mining Three Body Problem . https://www.aniccaresearch.tech/blog/bitcoin-minings-three-body-problem . finance . bitcoin, blockspace . ########## . The energy standard . https://medium.com/capriole/the-energy-standard-b726edeed588 . finance . bitcoin, blockspace . ########## . Bitcoin Energy Value Equivalence  . https://medium.com/capriole/bitcoin-value-energy-equivalence-6d00d1baa34a . finance . bitcoin, blockspace . ########## . Price transparency in the inflation swap market . https://www.newyorkfed.org/medialibrary/media/research/epr/2013/0513flem.pdf . finance . swaps . ########## . Blockspace: An introduction . https://www.generalist.com/briefing/blockspace . finance . blockspace . ########## . Controlling systems on a remote server . https://www.tecmint.com/control-systemd-services-on-remote-linux-server/ . engineering . systemd . ########## . Gold forwards and swaps . https://www.sunshineprofits.com/gold-silver/dictionary/gold-forwards-gold-swaps/ . finance . gold, swaps . ########## . Building a custom subscription in Geth . https://medium.com/@fejleuros/tutorial-1-part-4-70cddcc3b51d . engineering . blockchain, ethereum . ########## . Building a custom subscription in Geth . https://medium.com/@fejleuros/tutorial-1-part-1-350694af2632 . engineering . blockchain, ethereum . ########## . Building a custom subscription in Geth . https://medium.com/@fejleuros/quickie-session-1-7b585c33a9bf . engineering . blockchain, ethereum . ########## . Building a custom subscription in Geth . https://medium.com/@fejleuros/quickie-session-2-ea4e095b3fba . engineering . blockchain, ethereum . ########## . Building a custom subscription in Geth . https://medium.com/@fejleuros/tutorial-1-part-2-523cab272f8d . engineering . blockchain, ethereum . ########## . Building a custom subscription in Geth . https://medium.com/@fejleuros/tutorial-1-part-3-b23f1af0ca94 . engineering . blockchain, ethereum . ########## . Security Budget II, Low fees and Merged Mining . https://www.truthcoin.info/blog/security-budget-ii-mm/ . finance . bitcoin, blockchain . ########## . 50 takeaways from my time in venture . https://confluencevcweekly.beehiiv.com/p/50-brutally-honest-takeaways-time-venture-capital . finance . equity, venture . ########## . Doordash and Pizza Arbitrage . https://www.readmargins.com/p/doordash-and-pizza-arbitrage . finance . arbitrage, startups . ########## . Rollups hit the sweet spot . https://dinoeggs.substack.com/p/why-rollups-hit-the-sweet-spot . finance . blockchain, rollups . ########## . Rougelike Rust Tutorial . https://bfnightly.bracketproductions.com/rustbook/chapter_0.html . engineering . rust . ########## . Monitoring tiny web services . https://jvns.ca/blog/2022/07/09/monitoring-small-web-services/ . engineering . devops, startups . ########## . Architecture designs in Neon . https://neon.tech/blog/architecture-decisions-in-neon/ . engineering . devops, startups . ########## . sj.land . https://www.sj.land/ . manufacturing . items . ########## . No token apps: an alternative vision for the blockchain . https://firasd.substack.com/p/no-token-apps-an-alternate-vision . finance . blockchain . ########## . Modular Blockchains a Deep Dive . https://volt.capital/blog/modular-blockchains . engineering . blockchain, rollups . ########## . Indie Micro Blogging . https://book.micro.blog/ . lifestyle . blogging, perpetuals . ########## . Into RAFT Consensus . https://www.hashicorp.com/resources/raft-consul-consensus-protocol-explained . engineering . consensus, hashiorp . ########## . Why American cannot build . https://www.palladiummag.com/2022/06/09/why-america-cant-build/ . political . america, opinon, public infrastructure . ########## . How to make a complete map of every thought you think . https://users.speakeasy.net/~lion/nb/html/ . lifestyle . blogging . ########## . How we build a $1mm ARR SaaS . https://plausible.io/blog/open-source-saas . engineering, finance . startups . ########## . Responding to Beggars . https://stallman.org/articles/responding-to-beggars.html . philosophy . opinon, political . ########## . Lightweight Travel Guide . https://goldenlight.mirror.xyz/eq6soISEqTa1LcF6IgIQZIcFA4oaLw8TFjUnflkuqwg . lifestyle . travel . ########## . What would a chromium only web look like? . https://www.mnot.net/blog/2022/06/22/chromium-only . engineering . web . ########## . Orbits Approach to Engineerng . https://urbit.org/blog/precepts . engineering . decentralization . ########## . My personal Infrastructure . https://writings.stephenwolfram.com/2019/02/seeking-the-productive-life-some-details-of-my-personal-infrastructure/ . lifestyle . knowledge base, organization . ########## . Market Microstructure and the Roll Model . https://web.archive.org/web/20130210042725/http://www.statalgo.com/2012/10/07/market-microstructure-3-the-roll-model-1984/ . finance . market making, market micro-structure . ########## . Market microstructure and HFT  . https://web.archive.org/web/20130210040805/http://www.statalgo.com/2012/07/08/market-microstructure-and-high-frequency-trading-part-1 . finance . market making, market micro-structure . ########## . Market microstructure pt. 2 . https://web.archive.org/web/20130212152235/http://www.statalgo.com/2012/08/05/market-microstructure-2-an-overview/ . finance . market making, market micro-structure . ########## . Certus One Validator Operations Guide . https://kb.certus.one/ . engineering . blockchain, devops . ########## . Writing down what I do in Obsidian . https://v5.chriskrycho.com/journal/writing-down-what-i-do-in-obsidian/ . productivity . writing . ########## . Organizing my Software Projects . https://v5.chriskrycho.com/journal/organizing-many-software-projects/ . productivity . writing . ########## . What can you do with 10 minutes . https://v5.chriskrycho.com/journal/what-i-can-i-do-with-10-minutes/ . productivity . working . ########## . Flow State . https://v5.chriskrycho.com/journal/flow-state/ . productivity . working . ########## . Containers are chroot with fancy marketing . https://earthly.dev/blog/chroot/ . engineering . containers . ########## . Tailscale Funnel . https://tailscale.com/blog/introducing-tailscale-funnel/ . engineering . vpn . ########## . Spread Volatility and Volume’s relationship in market making . https://arxiv.org/pdf/1606.07381.pdf . finance . market making . ########## . Optimal High Frequency Market Making . https://stanford.edu/class/msande448/2018/Final/Reports/gr5.pdf . finance . market making . ########## . Network Quality of Service in Docker Containers . https://www.eecis.udel.edu/~adusia/papers/NetworkQoSDockerPaper.pdf . engineering . containers, docker . ########## . The Omnibus Model for Custody . https://medium.com/@FidelityDigitalAssets/the-omnibus-model-for-custody-96b69710f92d . engineering, finance . custody . ########## . Efficient Blockspace Allocations . http://www.nikete.com/Gas . finance . blockspace . ########## . Affect of Matching Algorithm Changes . https://www.cftc.gov/sites/default/files/2019-03/Two%20Year%20Analysis_updated%20-%20ada.pdf . finance . market making . ########## . Seiko Competition . https://www.plus9time.com/seiko-the-neuchtel-chronometer-competition . lifestyle . watches . ########## . The semiconductor watering hole . https://asianometry.substack.com/p/imec-the-semiconductor-watering-hole . finance . semiconductors . ########## . How non bank lending is shaping the economy . https://www.finleycms.com/how-non-bank-lending-is-reshaping-the-economy . finance . bank, lending . ########## . Using Rust at a Startup: A cautionary tale . https://mdwdotla.medium.com/using-rust-at-a-startup-a-cautionary-tale-42ab823d9454 . engineering . rust, startup . ########## . Beating the broadcast delay in the world cup . https://blog.benjojo.co.uk/post/beating-the-broadcast-delay-world-cup . engineering . latency, networking . ########## . Nothing Works . https://danluu.com/nothing-works/ . engineering . startup . ########## . How I became an honest broker . https://tedgioia.substack.com/p/how-i-became-the-honest-broker . finance . market making . ########## . Startup Ideas . https://www.gwern.net/Startup-ideas . engineering . startup . ########## . Mechanical Watch . https://ciechanow.ski/mechanical-watch/ . engineering . watches . ########## . Crypto Margin Perps . https://github.com/0xNineteen/blog.md/blob/master/crypto-margin-perps/index.md . finance . perpetuals . ########## . An Initial Approach to Order Flow Auction Design . https://collective.flashbots.net/t/frp-20-an-initial-approach-to-order-flow-auction-design/789 . engineering, finance . market making, market micro-structure, orderflow . ########## . Low Latency Optimization: Understanding Huge Pages (Part 1) . https://www.hudsonrivertrading.com/hrtbeat/low-latency-optimization-part-1/ . engineering, finance . market making, market micro-structure, orderflow . ########## . Bitcoin microstructure . https://markrbest.github.io/btc-microstructure/ . engineering, finance . crypto, market making, market micro-structure . ########## . Adventures in Horse Racing . https://markrbest.github.io/adventures-in-horse-racing/ . engineering, finance . sports betting . ########## . Bitcoin Elasticity and Volatility . https://markrbest.github.io/bitcoin-elasticity-and-market-crashes/ . engineering, finance . crypto, market making, market micro-structure . ########## . Volatility and Noise . https://markrbest.github.io/volatility-and-noise/ . engineering, finance . market making, market micro-structure . ########## . Fast Logging in Rust . https://markrbest.github.io/fast-logging-in-rust/ . engineering, finance . hft, rust . ########## . HFT and Rust . https://markrbest.github.io/hft-and-rust/ . engineering, finance . hft, rust . ########## . All is Fair in Arb and MEV on Avalanche C-Chain . https://www.ddmckinnon.com/2022/11/27/all-is-fair-in-arb-and-mev-on-avalanche-c-chain/ . engineering, finance . mev . ########## . Using ChatGPT as a Co-Founder . https://www.atomic14.com/2022/12/05/using-chatgpt-as-a-co-founder.html . engineering . chatgpt, startups . ########## . Why “Prompt Engineering” and “Generative AI” are overhyped . ########## . Why “Prompt Engineering” and “Generative AI” are overhyped . https://lspace.swyx.io/p/why-prompt-engineering-and-generative . engineering . chatgpt, prompt engineering, tailscale . ########## . Uniting rollups with shared sequencers . https://www.alexbeckett.xyz/uniting-rollups-with-shared-sequencers/ . engineering . l2, rollups . ########## . Risk frees and currencies: Part Three . https://nopeitslily.substack.com/p/risk-frees-and-currencies-part-three . finance . currencies, rates . ########## . What is GPT-4 . https://pub.towardsai.net/what-is-gpt-4-and-when-9f5073f25a6d . engineering . AI . ########## . Yield Space: Virtualizing inaccessible reserves . https://medium.com/napier-finance/yield-space-virtualizing-inaccessible-reserves-42b42af933f5 . finance . defi . ########## . The GPT-3 Architecture, on a Napkin . https://dugas.ch/artificial_curiosity/GPT_architecture.html . engineering . AI . ########## . Go and Nix Flakes . https://xeiaso.net/blog/nix-flakes-go-programs . engineering . go, nix . ########## . Pyth: A New Model to the Price Oracle . https://pythnetwork.medium.com/pyth-a-new-model-to-the-price-oracle-82a587e35f90 . engineering, finance . oracles . ########## . Messi is Impossible . https://fivethirtyeight.com/features/lionel-messi-is-impossible/ . sports . soccer, statistics . ########## . Liquidity providers, options and AMMs . https://medium.com/@odtorson/liquidity-providers-options-and-amms-c5e4ca50819e . finance . AMM . ########## . How does GPT get its Ability? . https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1 . engineering . AI . ########## . When did our tools become our religion? . https://vanschneider.com/blog/youre-using-the-wrong-design-tool/ . engineering . as-code . ########## . Fundamentals of Exchange Design . https://www.alphalab.capital/fundamentals-of-exchange-design/ . engineering, finance . exchange, market micro-structure . ########## . I built an AI chatbot based on my favorite podcast . https://every.to/superorganizers/i-trained-a-gpt-3-chatbot-on-every-episode-of-my-favorite-podcast . engineering . AI . ########## . Block vs. Slot PBS . https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ . engineering . block building, blockspace . ########## . A newspaper vanished from the internet . https://archive.vn/MgAsS . opinion . media . ########## . I asked ChatGPT to explain some jokes to me . https://susam.net/maze/chatgpt-explains-jokes.html . engineering . AI . ########## . The story of vaccinateca . https://www.worksinprogress.co/issue/the-story-of-vaccinateca/ . health . covid, politics . ########## . Data collection infrastructure . https://lightcycle.xyz/data-collection-intrastructure/ . engineering . market making . ########## . Reversing the EVM . https://degatchi.com/articles/reading-raw-evm-calldata . engineering . evm . ########## . Reverse Engineering Github copilot . https://thakkarparth007.github.io/copilot-explorer/posts/copilot-internals . engineering . AI . ########## . Comprehensive Rust . https://google.github.io/comprehensive-rust . engineering . rust . ########## . AI Chatbots are not a replacement for Search Engines . https://iai.tv/articles/all-knowing-machines-are-a-fantasy-auid-2334 . engineering . AI . ########## . Meet the Customer Service Reps for Disney and Airbnb Who Have to Pay to Talk to You . https://www.propublica.org/article/meet-the-customer-service-reps-for-disney-and-airbnb-who-have-to-pay-to-talk-to-you . finance . customer service . ########## . Digital Gardening in Obsidian . https://bytes.zone/posts/digital-gardening-in-obsidian/ . lifestyle . digital gardening . ########## . API Versioning: Stripe . https://stripe.com/blog/api-versioning . engineering . API . ########## . The Age of Industrialized AI . https://danieljeffries.substack.com/p/the-age-of-industrialized-ai . engineering . AI . ########## . I tried to buy a Rolex and fell into the Grey Market . https://archive.ph/cnTOV . lifestyle . watches . ########## . Approaches to MEV: Ethereum vs. Cosmos . https://www.reverie.ooo/post/approaches-to-mev-ethereum-vs-cosmos . engineering . mev . ########## . Jane Street: Mock Interview . https://www.janestreet.com/mock-interview/ . engineering . hft, interview . ########## . MEV: The first 5 years . https://medium.com/@Prestwich/mev-c417d9a5eb3d . engineering . mev . ########## . Does the Textual Corpus for Large Language Models Have Enough Information to Train an AGI? . https://shakoist.substack.com/p/does-the-textual-corpus-for-large . engineering . AI . 1/4/23 7:54 . Some remarks on LLMs . https://gist.github.com/yoavg/59d174608e92e845c8994ac2e234c8a9 . engineering . AI . 1/4/23 7:55 . You want modules not microservices . http://blogs.newardassociates.com/blog/2023/you-want-modules-not-microservices.html . engineering . devops . 1/4/23 7:54 . The Expanding Dark Forest and Generative AI . https://maggieappleton.com/ai-dark-forest . engineering . AI . 1/4/23 7:55 . The importance of python packaging  . https://pypackaging-native.github.io/ . engineering . package management . 1/4/23 7:55 . Production Twitter on one Machine . https://thume.ca/2023/01/02/one-machine-twitter/ . engineering . opinon . 1/9/23 7:14 . Shorting Tether for Fun and Profit . https://fakemoneynews.substack.com/p/shorting-tether-for-fun-and-profit . finance . market making . 1/9/23 7:15 . Arxiv Explorer . https://arxivxplorer.com/ . engineering . AI . 1/9/23 7:14 . Best ChatGPT Resources . https://enchanting-trader-463.notion.site/Best-ChatGPT-Resources-101-94a7c6dbabcc4febbfb498c555d6ef5f . engineering . AI, awesome-list . 1/9/23 7:14 . Perspectives On Values, Needs, Liquidity and Aging . https://moontower.substack.com/p/perspectives-on-values-needs-liquidity . finance . market making, market micro-structure . 1/9/23 7:15 . High School Dropout Turned Quant Trader, Entrepreneur (Pre &amp; Post FTX Collapse) w/ Kasper Vandeloock . https://chatwithtraders.com/ep-251-kasper-vandeloock/ . finance . market making . 1/9/23 7:15 . Branchless Git . https://github.com/arxanas/git-branchless . engineering . devops . 1/9/23 7:16 . Cross-Chain Order Flow Auctions . https://variant.fund/articles/cross-chain-order-flow-auctions/ . engineering . blockspace, mev . ########## . Enterprise Restaurant Compute . https://medium.com/chick-fil-atech/enterprise-restaurant-compute-f5e2fd63d20f . engineering . devops . ########## . Market Annealing: Getting to $10M ARR in Very Early Markets . https://a16z.com/2023/01/11/market-annealing/ . finance . startup . ########## . Your tech stack is not the product . https://hoho.com/posts/your-stack-is-not-the-product/ . engineering . opinon . ########## . 99.999% of Your Ideas are Side-Project Ideas, Not Startup Ideas: Why Treating Them as Such Increases Follow-Through . https://thinkingthrough.substack.com/p/startups-and-side-projects . engineering . startup . ########## . A Brief User Journey from AIGC . https://aiko.substack.com/p/a-brief-user-journey-from-aigc?utm_source=profile&amp;utm_medium=reader2 . engineering . AI . ########## . Further Binance-Peg Token Problems . https://datafinnovation.medium.com/further-binance-peg-token-problems-8db6a2cc20c3 . finance . stablecoins . ########## . Resending: “Well now you’re just making stuff up…” . https://michaelwgreen.substack.com/p/resending-well-now-youre-just-making?utm_campaign=auto_share . finance . markets . ########## . Is dev compensation bimodal? . https://danluu.com/bimodal-compensation/ . engineering, finance . compensation . ########## . Programmer salaries in the age of LLMs . https://milkyeggs.com/?p=303 . engineering, finance . compensation . ########## . GPT-3 Is the BestJournal I’ve Ever Used . https://every.to/superorganizers/gpt-3-is-the-best-journal-you-ve-ever-used . engineering . AI . ########## . Understanding Implied Forwards . https://moontowermeta.com/understanding-implied-forwards/ . finance . forward-contracts . ########## . An Exploratory Visual for Tracking Flow of Funds on Blockchain . https://medium.com/etherscan-blog/an-exploratory-visual-for-tracking-flow-of-funds-on-blockchain-fbeba2a761f3 . engineering . transaction tracing . ########## . Make Big Money Mistakes Early . https://blog.nateliason.com/p/lose-money-early . finance . opinon . ########## . Must ride mule (to &amp; from) work location . https://www.deepsouthventures.com/must-ride-mule-to-from-work-location/ . finance . startup . ########## . We invested 10% to pay back tech debt; Here’s what happened . https://blog.alexewerlof.com/p/tech-debt-day . engineering . tech debt . ########## . For your next side project, make a browser extension . https://www.geoffreylitt.com/2023/01/08/for-your-next-side-project-make-a-browser-extension.html . engineering . startup . ########## . Modern Polars . https://kevinheavey.github.io/modern-polars/ . engineering . tools . ########## . The Essential Guide to Syndicates . https://resonance.substack.com/p/the-essential-guide-to-syndicates . finance . startup, syndicates . ########## . Drift Protocol Deep Dive . https://driftprotocol.notion.site/Drift-dAMM-deep-dive-ff154003aedb4efa83d6e7f4440cd4ab . engineering . defi . ########## . Hubble vAMM Invariant . https://experienced-healer-088.notion.site/Hubble-vAMM-CurveCrypto-Invariant-a37aa328c0104106a3047e85d8f08dd5 . engineering . defi . ########## . ",
    "url": "/Tools/Blog%20Posts.html",
    
    "relUrl": "/Tools/Blog%20Posts.html"
  },"1": {
    "doc": "Cosmos Tools",
    "title": "Building your tools and Cosmos",
    "content": "Since there is no official source for binary builds of Cosmos, validators and users have to build the node and client themselves. This is very good security-wise, and we hope it stays this way. Trusting another party to provide unaltered binary builds is very dangerous as you cannot easily verify whether the build hasn’t been backdoored. There have been plenty of cases of compromised supply chains in the past [1]. While Git repositories can also be backdoored, it’s a lot harder to do so due to without getting caught, since the repo is an immutable, replicated ledger (almost like - hah - a blockchain!) as long as the repository is regularly pulled by contributors. Docker containers: Docker containers (even with automatic builds) are no exception, in fact, while Docker support signatures, containers aren’t usually signed and Docker does not enforce signature verification by default. In this chapter, we will explain how to perform simple and reproducible builds of Cosmos’ gaiad and gaiacli as well as to maintain your own patches on top of the upstream sources. ",
    "url": "/Concepts/Building.html#building-your-tools-and-cosmos",
    
    "relUrl": "/Concepts/Building.html#building-your-tools-and-cosmos"
  },"2": {
    "doc": "Cosmos Tools",
    "title": "Performing reproducible builds",
    "content": "Reproducible builds ensure that two parties which build the same binary from the same source will get an identical binary. This makes it a lot easier to trust third party binaries, since they can be independently verified. It also makes it easier to trust your own builds. Go makes this particularly easy - Go builds are reproducible by default, as long as your build environment (including the compiler version and GOPATH) are identical. By pinning the exact version of each dependency, we can ensure identical build inputs. Todo . Explain why reproducible builds are important and add a simple guide to use the buildscripts . Here you can find example build scripts for reproducible Cosmos builds: Certus Build scripts . ",
    "url": "/Concepts/Building.html#performing-reproducible-builds",
    
    "relUrl": "/Concepts/Building.html#performing-reproducible-builds"
  },"3": {
    "doc": "Cosmos Tools",
    "title": "Maintaining a mirror/fork",
    "content": "In order to be able to easily carry patches and check the authenticity of the Cosmos repository, we always build from our local mirror of the cosmos-sdk repository (which also comes in handy when GitHub is down). Sometimes it might be necessary for you to apply small patchsets to the Cosmos node, for features like our custom HSM signer (HSM for Signing), modifications to the peer discovery code, or emergency bugfixes for exploits that you can’t wait for the upstream team to patch because they’re causing monetary losses right now. Even if you don’t plan to run a Cosmos fork most of the time, you should be prepared to do so on a short notice, if necessary. A plain mirror can simply be turned into a fork by just committing on top of the master, and doing rebases against origin/master when there’s a new release. We don’t recommend forking the code base unnecessarily - most of the time, it’s much better to create a PR against the upstream repository. However, you sometimes need to maintain internal modifications - if you do so, try to keep them as small, nonintrosive and self-contained as possible, and in places where the code doesn’t change often to avoid large merge conflicts when rebasing onto upstream master. This article is a great introduction on how to maintain a fork: How to maintain a fork . For the Cosmos use-case, it might also make sense to mirror/fork Tendermint. You will need to add a [source] directive to the Gopkg.toml in the cosmos-sdk project to pull your Tendermint fork, and either commit the modified lockfile to your cosmos-sdk repo or do a full dep ensure run at build time (not recommended). ",
    "url": "/Concepts/Building.html#maintaining-a-mirrorfork",
    
    "relUrl": "/Concepts/Building.html#maintaining-a-mirrorfork"
  },"4": {
    "doc": "Cosmos Tools",
    "title": "Cosmos Tools",
    "content": " ",
    "url": "/Concepts/Building.html",
    
    "relUrl": "/Concepts/Building.html"
  },"5": {
    "doc": "Business Continuity",
    "title": "Business Continuity",
    "content": "While slightly less exciting than tech, business continuity plans are just as important as proper systems engineering, the latter being of little use if the company owning the servers goes under. International service provider standards like ISO 27001 call not only for technical, but also many organizational measures. We’ll highlight some of the most important ones. Note . Disclaimer: In some countries, laws are tricky as far as legal advice goes - so let’s make it clear that none of this is legal advice. This document is not a complete treatise on business continuity, and there’s some aspects that it doesn’t discuss (like insurance, liability risks, company structure…). Most importantly, we’re neither lawyers, nor corporate consultants. It’s a list of keywords to discuss with your cofounders (and lawyers), not an exhaustive checklist to follow. There’s a whole body of work on the topic of business continuity, corporate best practices and risk management as well as multiple ISO standards - this is just scratching the surface. ",
    "url": "/Concepts/Business%20Continuity.html",
    
    "relUrl": "/Concepts/Business%20Continuity.html"
  },"6": {
    "doc": "Business Continuity",
    "title": "Shareholder agreements",
    "content": "All of Certus One’s founders fully trust each other, have a long history of working together and neither of us has any intention to walk away. However, we still need to consider the risk of either of us quitting or us falling out with each other, and protect our company and our customers from this risk. There are many examples of companies meeting an untimely end due to trivial disagreements or founders leaving early while keeping significant stock in the company, making life difficult for the remaining founders when they want to bring in additional investors or sell the company. This is why it’s essential to have a carefully designed shareholder contract with clearly defined responsibilities (prevent many disagreements from occuring in the first place), and contingency clauses, designed by a specialized lawyer. While expensive, especially when you’re just getting started, having a solid foundation is very important - you’ll be stuck with it for a long time, and modifying those contracts at a later point is annoying and a lot more expensive. ",
    "url": "/Concepts/Business%20Continuity.html#shareholder-agreements",
    
    "relUrl": "/Concepts/Business%20Continuity.html#shareholder-agreements"
  },"7": {
    "doc": "Business",
    "title": "Business",
    "content": "All of Certus One’s founders fully trust each other, have a long history of working together and neither of us has any intention to walk away. However, we still need to consider the risk of either of us quitting or us falling out with each other, and protect our company and our customers from this risk. There are many examples of companies meeting an untimely end due to trivial disagreements or founders leaving early while keeping significant stock in the company, making life difficult for the remaining founders when they want to bring in additional investors. This is why it’s essential to have a carefully designed shareholder contract with clearly defined responsibilities (prevent many disagreements from occuring in the first place). Business continuity plans are just as important as proper systems engineering, the latter being of little use if the company owning the servers goes under. | Vesting schedule | Shoot out | . ",
    "url": "/Concepts/Business.html",
    
    "relUrl": "/Concepts/Business.html"
  },"8": {
    "doc": "CoreOS",
    "title": "CoreOS",
    "content": "https://blog.scottlowe.org/2014/08/01/a-quick-introduction-to-coreos/ . https://www.slideshare.net/RichardLister/core-os . https://danielcompton.net/modular-integrated-docker-coreos . http://www.asymco.com/2010/11/15/law-of-conservation-of-modularity/ . ",
    "url": "/Tools/CoreOS%2038d7c619ca894417aa08c624154e4f05.html",
    
    "relUrl": "/Tools/CoreOS%2038d7c619ca894417aa08c624154e4f05.html"
  },"9": {
    "doc": "Grafana",
    "title": "Grafana",
    "content": " ",
    "url": "/Tools/Grafana%2077a16aee0ed046b2a0d38896117bae4f.html",
    
    "relUrl": "/Tools/Grafana%2077a16aee0ed046b2a0d38896117bae4f.html"
  },"10": {
    "doc": "Grafana",
    "title": "Overview",
    "content": "Grafana is an open observability stack that also consists of Prometheus and Loki. Grafana gathers and allow visualization and alerting on the metrics and logging that are provided by the other parts of the observability stack. Other parts of Grafana’s observability stack include products like Mimir (long term storage for prometheus), OnCall (a call management tool, similar to PagerDuty), and k6 (load testing) . Selected Dashboards . | AWS Billing | Loki Logging Dashboard | Hardware Monitoring | Container Dashboard | Systemd | . ",
    "url": "/Tools/Grafana%2077a16aee0ed046b2a0d38896117bae4f.html#overview",
    
    "relUrl": "/Tools/Grafana%2077a16aee0ed046b2a0d38896117bae4f.html#overview"
  },"11": {
    "doc": "Grafana",
    "title": "Articles",
    "content": "List . ",
    "url": "/Tools/Grafana%2077a16aee0ed046b2a0d38896117bae4f.html#articles",
    
    "relUrl": "/Tools/Grafana%2077a16aee0ed046b2a0d38896117bae4f.html#articles"
  },"12": {
    "doc": "HSM for Signing",
    "title": "HSM for Signing",
    "content": "To ensure high security of your validator, you will want to sign your votes and block proposals using a HSM. ",
    "url": "/Concepts/HSM.html",
    
    "relUrl": "/Concepts/HSM.html"
  },"13": {
    "doc": "HSM for Signing",
    "title": "Why use a HSM",
    "content": "Tendermint introduction . In the Tendermint consensus, all validators in the active validator set participate by submitting block proposals and voting on them (using prevotes and precommits). The vote of your validator is authenticated using a cryptographic signature, so that other people know that the vote came from you and no one can impersonate you (which would break the consensus mechanism). This coordinated consensus, which is split into several steps, ensures that at least 2/3+ of the validators have the same view of the network since it requires 2/3+ votes for a block in order to finalize it. With this restriction in place, we would assume that it is impossible for two different chains (forks) to exist a time, since it is not possible to get 2 times 2/3+ votes on two conflicting blocks in a 3/3 validator set. Double signing . However, this excludes the scenario of double voting/proposing. In this scenario, the byzantine proposer in the consensus round creates two conflicting blocks and sends them out to the network. If we assume that we also have other byzantine actors in the validator set which want to profit from both chains, these will also vote for both blocks. That means that honest nodes in the network could see 2 different blocks at the same height with different contents and hashes. From this point on the network has forked. Outside viewers of the network will not know which block is correct and from now on there will not be a single truth. This is the exact scenario we want to prevent with PBFT-like consensus systems. How Cosmos prevents forks . Now that we know the reason that causes forks: . | Conflicting votes by the same validator | . It can be summarized as double signing. In order to create two conflicting votes, a validator needs to sign two consensus messages for the same HRS pair with its key. Tendermint allows other validators to record evidence of byzantine behaviour in blocks. Cosmos makes use of this features and slashes validators that double sign. At the moment, the slashing rate is set to 5% of all bonded Atoms, which is very substantial amount. This strict slashing condition makes it extremely important for validators to avoid double signing in order to ensure network security and prevent being slashed. Problems of the default signing implementation . Lets assume a scenrio in which your validator host is compromised by a malicious actor who wants to financially hurt you and your customers (people staking tokens with you). If you are using the default FilePV, which stores the private key associated with your validator on the file system, the attacker can compromise your host and steal your priv_validator.json file. From then on, he has the ability to sign any consensus message with your validator’s key. That way, the attacker could double sign on your behalf, triggering the slashing conditions for you forever since validator keys cannot currently be replaced, ruining your validator. For this reason, it’s crucial that your validator key cannot be stolen, even if your node is compromised. The solution . A HSM is a separate hardware component that stores keys and - unless configured to perform differently - will not allow you to extract the private keys it stores. However, it will use the private key to sign/encrypt data for you. HSMs use special tamper-proof secure elements which make it extremely hard to extract the secret keys, even with physical access. This allows you to store your validator private key on a HSM and not leave it exposed on the filesystem of the validator host. Using a special software component, Tendermint will ask the HSM to sign the consensus message without ever handling the private key itself. In case of validator compromise, the attacker would not be able to extract your private key and he could only make you double sign as long as he controls your host. This can be further mitigated by having an encrypted session between Tendermint and the HSM and doing proper secrets management. With such measures in place, it would be harder for a validator to get the HSM to sign arbitrary data and you would have more time to detect and mitigate the attack. ",
    "url": "/Concepts/HSM.html#why-use-a-hsm",
    
    "relUrl": "/Concepts/HSM.html#why-use-a-hsm"
  },"14": {
    "doc": "HSM for Signing",
    "title": "HSM implementations",
    "content": "KMS by Tendermint . KMS (Key Management Service) is a reference implementation of pluggable signing modules in a separate software component, maintained by Tendermint. KMS is a separate process which handles signing and implements double signing protection (like keeping track of the last signed messages). This component communicates with the Tendermint node using a encrypted channel to prevent MITM attacks. Signers are implemented as plugins which makes is very extensible and flexible. Examples of implemented signers include the YubiHSM2, Ledger Nano S and the traditional file signer mentioned above. The advantage of running a separate host (or an SGX enclave) for key management is that in case of a validator host compromise, your KMS host will remain secure and the built-in double signing protection in the KMS will prevent it from responding to double signing requests from the compromised validator host. At the time of writing, the KMS service is actively being developed and not yet ready to be used. You can watch the progress and contribute here in the KMS Github repository. Aiakos by Certus One . While KMS connects to Tendermint via a socket, Aiakos is an in-process signer implementation and compiled into gaiad. Aiakos uses the PrivValidator interface of Tendermint to implement a direct wrapper to the YubiHSM2. We also implemented a YubiHSM Go library. In order to use Aiakos, you have to install the Yubico YubiHSM2 connector on your host and apply a small patch your Cosmos node source to register it (a validator should always build their own cosmos-sdk binaries - see the article on building Cosmos). Your Cosmos node will then attempt to connect to the YubiHSM and optionally import a key specified by you to the HSM. All consensus messages will then be signed using the HSM. We initially designed Aiakos as part of our proprietary JANUS active-active validator, but it can also be used as a standalone signer. We found the socket interface to be too unreliable, and KMS not ready for production, so we set out to build a minimal, easily audited YubiHSM 2 PrivValidator. We chose to write it in Go to avoid the extra complexity of using Rust, which we thought offered little tangible security benefits over Go in this use case. By being in-process, Aiakos is much more reliable, but slightly less secure than KMS since it doesn’t implement double signing protection in the event of a validator compromise. We decided that, for now, using the socket interface with the pre-release KMS software poses a greater risk than the (unlikely, given the minimal attack surface for remote code execution) event of an attacker somehow compromising the validator host, but not the KMS host unless completely separate infrastructure is used for KMS. Tendermint is written in Go, which is a memory-safe language, making remote code execution highly unlikely. Most threat scenarios would involve a full infrastructure compromise, like a compromised workstation, supply chain or operating system vendor. The remaining issue of logic errors which would trick the validator into double signing can be mitigated using double-signing prevention which we implemented at the JANUS layer. However, we do believe that high-assurance double-signing prevention is worth pursuing, and we plan to either switch JANUS to KMS once it’s ready, and/or work with the community to improve support for out-of-process signers and move Aiakas and JANUS to an out-of-process model. That being said, this will only provide a tangible security advantage if the out-of-process signer itself runs in an isolated environment like SGX and is able to replicate state to standby instances in a high-availability setup. ",
    "url": "/Concepts/HSM.html#hsm-implementations",
    
    "relUrl": "/Concepts/HSM.html#hsm-implementations"
  },"15": {
    "doc": "HSM for Signing",
    "title": "How to setup a Cosmos validator with Aiakos YubiHSM2 support",
    "content": ". | Clone cosmos-sdk and checkout the version you want to use. | Modify the file server/start.go and insert this code in the startInProcess function, before “// create &amp; start tendermint node” | . if os.Getenv(“AIAKOS_URL”) == “” { return nil, errors.New(“no Aiakos hsm url specified. Please set AIAKOS_URL in the format host:port”) } aiakosUrl := os.Getenv(“AIAKOS_URL”) if os.Getenv(“AIAKOS_SIGNING_KEY”) == “” { return nil, errors.New(“no Aiakos signing key ID specified. Please set AIAKOS_SIGNING_KEY”) } aiakosSigningKey, err := strconv.ParseUint(os.Getenv(“AIAKOS_SIGNING_KEY”), 10, 16) if err != nil { return nil, errors.New(“invalid Aiakos signing key ID.”) } if os.Getenv(“AIAKOS_AUTH_KEY”) == “” { return nil, errors.New(“no Aiakos auth key ID specified. Please set AIAKOS_AUTH_KEY”) } aiakosAuthKey, err := strconv.ParseUint(os.Getenv(“AIAKOS_AUTH_KEY”), 10, 16) if err != nil { return nil, errors.New(“invalid Aiakos auth key ID.”) } if os.Getenv(“AIAKOS_AUTH_KEY_PASSWORD”) == “” { return nil, errors.New(“no Aiakos auth key password specified. Please set AIAKOS_AUTH_KEY_PASSWORD”) } aiakosAuthPassword := os.Getenv(“AIAKOS_AUTH_KEY_PASSWORD”) // Init Aiakos module hsm, err := aiakos.NewAiakosPV(aiakosUrl, uint16(aiakosSigningKey), uint16(aiakosAuthKey), aiakosAuthPassword, ctx.Logger.With(“module”, “aiakos”)) if err != nil { return nil, err } // Start Aiakos err = hsm.Start() if err != nil { return nil, err } if os.Getenv(“AIAKOS_IMPORT_KEY”) == “TRUE” { ctx.Logger.Info(“importing private key to Aiakos because AIAKOS_IMPORT_KEY is set.”) filepv := pvm.LoadOrGenFilePV(cfg.PrivValidatorFile()) key := filepv.PrivKey.(ed25519.PrivKeyEd25519) err = hsm.ImportKey(uint16(aiakosSigningKey), key[:32]) if err != nil { ctx.Logger.Error(“Could not import key to HSM; skipping this step since it probably already exists”, “error”, err) } } . | Add import for \"github.com/certusone/aiakos\", \"github.com/tendermint/tendermint/crypto/ed25519\", \"os\" and \"strconv\" to the file’s import section. | Replace pvm.LoadOrGenFilePV(cfg.PrivValidatorFile()) with hsm (keep the comma at the end of the line) | Run dep ensure -v | Build cosmos as described in the README | Install the YubiHSM connector on the host machine | Run the YubiHSM connector (we recommend a sytemd service unit) | Update AuthKeys and generate a EdDSA signing-key on the HSM (optional) | . Now you can run your Cosmos node with HSM support. You need to set the following environment variables when running your node: . AIAKOS_URL . The URL of the YubiHSM connector. Usually localhost:12345 . AIAKOS_AUTH_KEY . The ID of the Auth Key. Default 1 . AIAKOS_AUTH_KEY_PASSWORD . The password of the Auth Key. Default “password” . AIAKOS_SIGNING_KEY . The ID of the signing key. The one you generated before or a free slot. AIAKOS_IMPORT_KEY . Do you want to import your priv_validator.json to the HSM. “TRUE” if yes . Todo . Provide a patchset which applies on top of the latest cosmos-sdk master . ",
    "url": "/Concepts/HSM.html#how-to-setup-a-cosmos-validator-with-aiakos-yubihsm2-support",
    
    "relUrl": "/Concepts/HSM.html#how-to-setup-a-cosmos-validator-with-aiakos-yubihsm2-support"
  },"16": {
    "doc": "HSM for Signing",
    "title": "HSM hardware",
    "content": "For the sake of diversity, the Cosmos community shoudn’t rely on a single HSM and we hope that more vendors will add EdDSA support to their HSMs. Aiakos is a great starting point for validators who want to implement a custom signer for a new type of HSM. YubiHSM2 . The YubiHSM2 by Yubico is the most commonly used HSM among Cosmos validators. It is quite affordable and is among the (very) few HSMs which supports EdDSA. The HSM runs from a USB port. We recommend you to use an internal USB port for better protection against accidental damage as well as physical security considerations. [1] . Hardware Security Module . [2] . state of the blockchain, transactions and application . [3] . containing different transactions, e.g. double-spending . [4] . pair of (block-) height, (consensus-) round, (consensus-) step . [5] . malicious . [6] . man-in-the-middle . ",
    "url": "/Concepts/HSM.html#hsm-hardware",
    
    "relUrl": "/Concepts/HSM.html#hsm-hardware"
  },"17": {
    "doc": "Key Management",
    "title": "Key Management",
    "content": "For validator operations, you need two types of keys in the Cosmos network. Validator Key . As discussed in HSM for Signing, this key is used by your nodes to participate in the Tendermint consensus. Account Key . This key for your Cosmos account. The account holds your validator’s balances and claim rights for rewards. This is the account you initially bonded your validator with, and can also unbond it with. As the handling of the Validator Key has already been addressed in the HSM article, we will now focus on the Account Key. ",
    "url": "/Concepts/Key%20Management.html",
    
    "relUrl": "/Concepts/Key%20Management.html"
  },"18": {
    "doc": "Key Management",
    "title": "Handling of the Account Key",
    "content": "The Account Key is required once to initially bond your validator. Afterwards in validator operations it is only needed to: . | Vote on governance proposals | Create governance proposals from your validator’s identity | Unbond your validator’s self-bond | Unrevoke the validator | Bond more ATOMs from the validator’s balance | Transfer ATOMs from your validator’s balance (if they are stored in the validator account) | Modify validator details (moniker, commission) | Sign any transaction from this account | . As we can see, the key is needed for many important validator tasks. Some of these look easy to automate like voting on governance and bonding rewards. However, the key’s capabilities include unbonding your validator’s self-bond, modify the validator and transfer funds, which makes it highly critical. The account key basically indicates the ownership of the validator. It is very important to protect and safeguard the key. It quickly becomes apparent that you don’t want to keep this key on an online machine - especially not stored on a normal machine like in the (encrypted) format of gaiacli. ![images/ledger.jpg](_images/ledger.jpg) “IMG_7984” by Dennis Amith is licensed under CC BY-NC 4.0_ . A possibility introduced by the Cosmos Team is the Ledger Nano S. It is a hardware wallet that stores the private key of your validator account just like a HSM without any possibility for you to extract the key (except for the backup phrase generated during setup). Support for the Ledger is built into the latest version of gaiacli. However, the Ledger App is still not in the public application store and has to be installed manually. In order to sign a transaction or message you need to click a physical button on the Ledger and are also able to check the authenticity of the transaction content on the display to prevent any attacks even on a compromised system. The added security is basically a no-brainer for every validator since losing the key basically means the death of the validator’s business. Drawbacks . The need to physically interact with the Ledger makes it mostly impossible to automate any of these tasks like auto-bonding or governance participation. Since the slashing for governance participation was removed [1], automatic governance participation is not necessary or useful - the voting period will be long enough for human interaction, which is the whole point of it - governance is not supposed to be automated, and the validator will want carefully assess each governance proposal. Auto-bonding and similar automation is of little use outside the Game of Stakes. Bonding involves large sums of money and should be a manual activity. [1] . https://github.com/cosmos/cosmos-sdk/pull/2395 . ",
    "url": "/Concepts/Key%20Management.html#handling-of-the-account-key",
    
    "relUrl": "/Concepts/Key%20Management.html#handling-of-the-account-key"
  },"19": {
    "doc": "Linux Configuration",
    "title": "Linux Best Practices",
    "content": "This article details some basic best practices for Linux server configuration. ",
    "url": "/Concepts/Linux%20Config.html#linux-best-practices",
    
    "relUrl": "/Concepts/Linux%20Config.html#linux-best-practices"
  },"20": {
    "doc": "Linux Configuration",
    "title": "Configuration management",
    "content": "You should strictly do all systems configuration through config management - it’s a investment that pays off almost immediately. Some companies go as far as disabling SSH access, though we consider that a bit extreme (you still need SSH login to debug). We recommend Ansible for being both simple and powerful - it has a good learning curve, is easy to reason about and it’s the fastest-growing tool with the largest community. There are some systems like Puppet which are more powerful, but also a lot more complicated. We’ve seen a pattern in devops team where there’s only a few “Puppet wizards” who know how to use it properly, with everyone else avoiding it. Ansible is less sophisticated - its execution model is sequential and it has no concept of resources, but it’s also much easier to use. This turns out to be a significant advantage, since it greatly lowers the barrier to entry and ensure the team is actually using the configuration management tool rather than trying to bypass it or getting the team’s resident wizards to implement features for them. Red Hat has bought Ansible and is moving many of its products away from Puppet. ",
    "url": "/Concepts/Linux%20Config.html#configuration-management",
    
    "relUrl": "/Concepts/Linux%20Config.html#configuration-management"
  },"21": {
    "doc": "Linux Configuration",
    "title": "User authentication",
    "content": "Unless you have dozens of users, you should provision a local user - including a password - for each team member using your favorite configuration management tooling and add the users to your sudo group (i.e. sudo or wheel, depending on distro). Make sure to use a password that’s not re-used for anything else, and only ever put the password hash into your config files (seems self-evident to a Linux admin, but did you know it’s impossible to set a user’s password hash on Windows?). Make sure to use consistent UIDs in the &gt;70000 range for each user - this prevents UID conflicts and consistency across all machines makes (make sure your UID range is outside of what is configured in /etc/login.defs). You need to treat each individual user like a root user - if the account were to be compromised, it would be trivial to escalate these privileges by adding a LD_PRELOAD backdoor (or similar) and waiting until the next time the user uses sudo. Then, disable the root user’s password by setting an invalid password hash (usually NP). This has a number of advantages: . | It’s a lot easier to audit each individual user’s actions on the server (see auditing section in the security article). auditd can associate SSH keys to user sessions, but that takes some work and isn’t 100% accurate. The user’s login/audit UID (auid) will be carried along through sudo and su invocations. | You can have your configuration management tool log into the server using its own user account, allowing you to easily filter out audit events caused by deployment. | Users can log into a server’s local console using their own password. | If a team member leaves, you don’t need to change a shared root password. | . If you have many different users, the overhead of adding local users on each machine will become notable and you might want to look into using something like sssd, though that will introduce additional complexity - how to ensure that you can still log into servers without network? . SSH authentication . Make sure to use public key authentication, and only public key authentication. Have a redundant set of bastion/VPN hosts and restrict SSH access to these hosts (along with any other potentially dangerous services). Don’t use SSH agent forwarding for your bastion host, instead, forward SSH sessions through the bastion host using plain OpenVPN, sshuttle or a ProxyCommand ssh_config directive. If your team is large, you probably want to use something like Teleport to tie SSH authentication and auditing into your existing, two-factor-secured single-sign-on solution. However, if your team is small, just hand everyone two YubiKey 4 tokens and use their OpenPGP feature for SSH authentication. Never use plain local SSH keys - they’re too easy to steal, and an attacker who has sufficient access to steal your keys can likely keylog the passphrase. They’re so cheap that there’s little excuse for not using them :-) . Don’t use fail2ban (it’s pointless with key auth and adds additional attack surface; Chinese bots shouldn’t be able to talk to your SSH service to begin with). Todo . How to use a YubiKey 4 for SSH authentication . ",
    "url": "/Concepts/Linux%20Config.html#user-authentication",
    
    "relUrl": "/Concepts/Linux%20Config.html#user-authentication"
  },"22": {
    "doc": "Linux Configuration",
    "title": "Choice of distribution",
    "content": "We recommend Red Hat Enterprise Linux (RHEL), CentOS or Debian, in that order. Red Hat’s quality assurance is the best in the industry - they are very diligent about release notes and backwards compatibility within a major release. They have an in-house kernel engineering team and are good at making sure their kernel works well on enterprise bare-metal server hardware. When the Spectre/Meltdown vulnerabilities hit, not only did they have a functional patch on day one, but they managed to develop it in-house despite not being able to discuss it with the Linux kernel community (due to a severely mismanaged vulnerability disclosure process). Red Hat is generally the fastest to respond to security vulnerabilities and has writeups detailing impact, workarounds and available patches. Red Hat’s support is top notch (once you get past the first level), and has direct access to Red Hat’s engineers. Needless to say, this is very valuable. Licensing is a hassle, but we recommend buying RHEL support if you can afford it - at least for your critical hosts (no, we’re not getting any sales commissions ;-)). CentOS is the community edition of RHEL. It used to be a separate project, but has since been assimilated by Red Hat. Due to the cooperation between Red Hat and CentOS, it barely lags behind the upstream releases. You don’t get any support, lesser assurances as far as supply-chain security goes and the packages have no security metadata (so you can’t set it to auto-install security updates, but you should have a proper patch management procedure, anyway), but it’s otherwise identical to RHEL. RHEL and CentOS have very long support periods of more than ten years - RHEL 6, released in 2010, is getting updates until 2024. Debian is the community server linux distribution and the other pole of the RPM/DEB ecosystem split. While it has a number of corporate sponsors nowadays - companies which use Debian and support it - it’s a volunteer-driven community project at its core, developed entirely in the open. The project is community-run, has a mature governance model and community manifesto, is independent of any single company, and - naturally - much less subject to corporate agendas than other distributions. It’s a conservative, slow-moving distribution just like RHEL. Security updates are usually fast, but depend a lot on individual maintainers and whether or not a particular issue is being handled by their security team. We’ve seen situations where less widely used packages with known security issues weren’t updated since its maintainer was unreachable, so be prepared to package and deploy your own security fixes (this applies to any distro - you should be able to build and sign your own packages). Debian releases are more frequent than RHEL and are only supported for 2-3 years, with the Debian LTS project continuing support for two more years. Debian has good QA and is a very solid choice, especially if you have team members who have a lot of experience with Debian-based distributions like Ubuntu, and none with RPM. Don’t expect it to be as polished as RHEL. Many things which work “out of the box” in RHEL are harder on Debian, especially enterprise features like auditing. Why not Ubuntu? . We do not recommend Ubuntu for production, especially if you’re going to run on it bare metal hardware. Ubuntu is a very common choice for devops teams, especially startups, so we’ll elaborate a little to explain why. We have had bad experiences with their quality assurance and have seen things breaking horribly in LTS releases. They’re still doing a great job, considering that they’re a much smaller company than Red Hat, but it’s not at the same level. Often, relatively simple bugs take years to fix. Canonical also has a habit of building their own solutions without ensuring backing of the wider Linux community. Those solutions then fail to be adopted by the community. This is a hit and miss strategy, and they often miss, leaving their customers scrambling to migrate to whatever the community settled on. This happened multiple times in the recent past: . | Eucalyptus was shelved in favor of OpenStack. | Bazaar - though some people still swear by it - was superseded by Git. | Upstart ended up being abandoned in favor of systemd (Ubuntu users had to first migrate to Upstart, then migrate again to systemd - wasn’t fun!). | Unity was abandoned for Gnome 3. | Ubuntu 14.04 LTS wasn’t released with the stable Linux kernel release at the time, but they chose to maintain their own stable kernel. | The Mir display server did not gain adoption and was replaced by Wayland. | Ubuntu One and Ubuntu Phone were discontinued. | Juju is basically unheard of outside the Ubuntu ecosystem, and will probably become irrelevant with the adoption of Kubernetes and Ansible. It’s also pretty crude (basically, a stateful collection of bash scripts) compared to something like Helm charts. | . It’s a shame some of these didn’t work out and hopefully they they learnt from it - the ecosystem would greatly benefit from better collaboration between Canonical and Red Hat. The latest case is Snappy vs Flatpak - right now, Snappy has a larger user base and commercial backing, but Flatpak is technically superior with OSTree, Portals and Wayland integration, focusing on deep integration with desktop applications, whereas Snappy is trying to be a general-purpose packaging mechanism, with an unclear relationship with Docker (which, for better or worse, is on track to become the actual general-purpose packaging mechanism). Part of the issue is that Canonical often fails to engage the community or doesn’t wait for community consensus. Their CLA adds a lot of friction and their Launchpad platform has bad usability compared to modern platforms, while many Red Hat projects are developed on GitHub, which people are more familiar with (they also have no CLA for most projects). That being said, the positive influence of Ubuntu Desktop on the desktop Linux ecosystem is hard to overstate. They were the first distribution to popularize desktop Linux and did a lot of hardware compatibility and user experience work. For the longest time, Ubuntu was the only major distribution which had acceptable font rendering out-of-the box. It’s the only popular desktop Linux distribution that offers long-term support. Applications vs OS divide . One common pain point with conservative distributions like Debian and RHEL is their slow pace - LTS distributions make promises of backwards compatibility, and any major upgrades within a major release are hard-to-impossible without breaking compatibility. For example, RHEL has - to many people’s surprise - been rebased on a newer OpenSSL release in 7 .4 in order to to enable HTTP/2. They had to rebuild half of all packages that depended on OpenSSL, which was a massive effort, and test them all to ensure they all were still working, and the only reason this was possible to begin with was that OpenSSL itself didn’t break backwards compatibility or change their API. Having a slow-moving, rock-solid operating system is critical for production, however, it’s painful for development. For this reason, we believe that attempts to develop and deploy applications against the distribution’s runtime and library are misguided (with the obvious exception of systems software which is part of the distribution). It’s impossible to reconcile the stability requirements of the operations side with developer’s need for the latest and greatest programming languages and libraries, both of which are reasonable. The right solution is to completely separate application runtime and operating system. A best example of this approach is Golang - Go binaries have no userland dependencies except for minimal usage of libc, and even that can be disabled. This also applies to the Go compiler - you can download the latest Go compiler and run it on any Linux kernel &gt;2.6.23. The same thing is possible with any other language runtime. Docker makes this even easier - containers ship their own userspace with minimal interaction with the host OS (mostly through the kernel). You can run a rock-solid host OS, while running Fedora or Ubuntu containers with the latest and greatest . ",
    "url": "/Concepts/Linux%20Config.html#choice-of-distribution",
    
    "relUrl": "/Concepts/Linux%20Config.html#choice-of-distribution"
  },"23": {
    "doc": "Linux Configuration",
    "title": "Custom software",
    "content": "Try to stick with your Linux disto repositories. Your Linux distro takes care of reviewing and maintaining the software, a tasks that would otherwise fall on you. If you need custom software outside of your distro’s repositories (and you will, sooner or later), do not install it manually/using make install. Ideally, you wouldn’t even have compilers on your production systems! Rather, build custom packages or Docker containers (whatever you’re more comfortable with - building DEB and RPM packages can be intimidating) . If you’re familiar with it, Certus One recommends a custom DEB/RPM package repository and signing infrastructure since it allows you to rebuild and deploy core packages, and doesn’t require any extra dependencies on your nodes. However, there’s nothing wrong with standardizing on Docker builds, especially if your team is familiar with Docker and you’re using it anyway, so you can avoid maintaining two separate build pipelines and delivery methods. You also need to keep track of all custom software you use in a software library - this can be as simple as a spreadsheet or internal Wiki page, but it’s crucial to have. The software library should list, at the very least: . | The software’s author and source. | The team member who is the internal “package maintainer”. | Instructions for building the package. | A mailing list or comparable channel for security bulletins - since your distro isn’t going to look out for security vulnerabilities, you will have to do so yourself. | . Having processes for maintaining and patching custom packages is very important - they are easily forgotten about. ",
    "url": "/Concepts/Linux%20Config.html#custom-software",
    
    "relUrl": "/Concepts/Linux%20Config.html#custom-software"
  },"24": {
    "doc": "Linux Configuration",
    "title": "Docker images",
    "content": "Build all Docker images from scratch. We strongly recommend against using pre-built Docker images in production, for multiple reasons: . | Experience shows that you’ll sooner or later need to modify the Docker containers you use, and you should be prepared by having a proper build . | . Certus One uses the OpenShift/okd build system and registry for container builds. If you build your own images, try to use the same operating system base image as your host OS, or at least the same operating system family (i.e. Fedora on CentOS, more recent Ubuntu releases on Ubuntu LTS). This makes it a lot easier for your team to debug containers since they’ll be familiar with the operating system, and it avoids introducing additional security dependencies. ",
    "url": "/Concepts/Linux%20Config.html#docker-images",
    
    "relUrl": "/Concepts/Linux%20Config.html#docker-images"
  },"25": {
    "doc": "Linux Configuration",
    "title": "Network time",
    "content": "We recommend using chronyd, a modern (and safer) alternative to ntpd. Many Linux distributions come with chronyd as the default. Do not use systemd-timedated - it’s great for . Time-keeping is extremely important for any modern protocol. Some databases like CockroachDB even rely on nanosecond-precision timestamps for global transaction ordering (and therefore consistency). If you can, configure each data center’s local time servers as preferred peers. Many high-end data centers will even have a local stratum This protects you against outside NTP . In case you run a database like CockroachDB, having a high-accuracy local time source is crucial. ",
    "url": "/Concepts/Linux%20Config.html#network-time",
    
    "relUrl": "/Concepts/Linux%20Config.html#network-time"
  },"26": {
    "doc": "Linux Configuration",
    "title": "DNS resolvers",
    "content": "Keep in mind that Linux has no DNS caching - it consults the resolver configured in /etc/resolv.conf on each lookup. Depending on the amount of lookups your application does, this can be really expensive. You need to ensure that you either: . | ..have a resolver very close in your local network (&lt;1ms) | ..or run a caching stub resolver on each host. | . If you have a local resolver, use that. Any cloud or datacenter provider will have local resolvers, and it’s one less thing you need to care about and deal with when it breaks. However, if you do a lot of DNS queries or need DNSSEC validation, or your local resolver is untrustworthy/unreliable, by all means, run a local forwarding resolver on each node and familiarize yourself with it. Here’s some common choices: . nscd . nscd is a generic caching daemon not only for DNS, but any NSS names, including local users and groups. It’s present on most systems, though seldom enabled by default. We do not recommend to use it, and to disable its DNS caching if you do use it for other reasons. It has very simplistic positive and negative caches, disregards the DNS TTL and many other parts of the DNS RFCs and likes to treat lookup failures as negative responses and cache them, resulting in hard-to-debug issues. We don’t recommend its use. If you need NSS caching, use the modern sssd instead. systemd-resolved . systemd-resolved does more than just manage /etc/resolv.conf - it also has its own NSS resolver implementation, nss-resolve. You can think of it as an advanced nscd that understands DNS TTLs and DNSSEC, but has little customization or security features on top of that. In particular, it’s designed as a stub resolver that forwards to a real resolver in the same network, and is not particularly resistant against network-level attacks. In particular, they do not employ source port randomization (which makes it easier to race against the reply from the upstream resolver) or bother validating certificates with DNS-over-TLS. We recommend systemd-resolved if all you need it caching and DNSSEC validation, and want to avoid pulling in an extra dependency like dnsmasq, and your risk model excludes or accepts attackers in the local network (as a validator, it probably doesn’t, and you might not want to use resolved). dnsmasq . dnsmasq is the most commonly used forwarding resolver (and DHCP server - make sure to disable that!). It’s well-audited, standards-compliant, DNSSEC-validating and has none of the drawbacks that systemd-resolved has, though it’s “just” a local resolver without fancy NSS integration. We recommend dnsmasq. unbound . Unbound is a full recursive DNSSEC-validating resolver which is able resolve domains by itself (by querying the root zone), without forwarding to a higher-tier resolver. While you can use it as a forwarding resolver, there’s little point in doing so. However, if you do want to run a full resolver, Unbound is what we recommend. DNS-over-TLS¶ . ",
    "url": "/Concepts/Linux%20Config.html#dns-resolvers",
    
    "relUrl": "/Concepts/Linux%20Config.html#dns-resolvers"
  },"27": {
    "doc": "Linux Configuration",
    "title": "Linux Configuration",
    "content": " ",
    "url": "/Concepts/Linux%20Config.html",
    
    "relUrl": "/Concepts/Linux%20Config.html"
  },"28": {
    "doc": "Monitoring",
    "title": "Monitoring, Alerting and Instrumentation",
    "content": "Monitoring is an integral part of providing highly available services. By monitoring, we mean: . | Instrumenting your applications and servers and collecting as many useful metrics as possible. Having detailed metrics is invaluable for debugging, incident response and performance analysis (observability - you can’t improve what you can’t measure). | Generating on-call alerts when a production system breaks and needs fixing. | Handling one-time events which need attention. | . Traditionally, most teams used different systems for metrics and alerting, with a time-series database like Graphite for metrics and a check-based monitoring system like Nagios for alerts. Nowadays, a different paradigm is getting popular - metrics-based alerting. Instead of having separate tooling for instrumentation and monitoring, alerts are realized by configuring rules that are evaluated against collected metrics. This is a very powerful approach, since it radically simplifies the monitoring stack and allows for sophisticated queries over time ranges and groups of metrics. Modern monitoring like Prometheus make modern metrics-based alerting very approachable. Gone are the days of fiddling with Nagios performance and check scripts! . However, no tool can solve the hardest part about monitoring - figuring out what to monitor and when to alert. As any on-call engineer can attest, the most common failure mode in alerting is having too many alerts, rather than too few, with important alerts getting lost in the noise. Therefore, the main goal of a good alerting system is a high signal-to-noise ratio - every alert should be relevant (impact a production system in a way that requires immediate attention), and actionable (require human input to resolve). Any condition that isn’t either relevant, or actionable, must not result in an alert. You also need to figure out whom to alert - also called on-call rotation, how to compensate for it, how to fairly distribute the load in the team, how to effectively communicate during an incident, and handle the feedback loop (we’ll dedicate a separate article to this topic). A low number of meaningful, simple alerts paired with robust business procedures which ensure that alerts are acted upon, false positives are quickly eliminated and outages are followed up are much more powerful than “magic” approaches like anomaly detection, which sound good in theory, but don’t work well in practice [1]. [1] . Anomaly detection - while useful in other contexts- tends to quickly break down for monitoring use cases. As soon as you compare a sufficiently large number of metrics, spurious correlations will show up and result in false positives. Your online shop saw a 10x traffic spike, but didn’t go down - why would you page someone? Everything is working fine. Simple time offsets (do we see less traffic than last week?), linear extrapolation and even fixed thresholds are much more specific. ",
    "url": "/Concepts/Monitoring.html#monitoring-alerting-and-instrumentation",
    
    "relUrl": "/Concepts/Monitoring.html#monitoring-alerting-and-instrumentation"
  },"29": {
    "doc": "Monitoring",
    "title": "Symptoms-Based Alerting",
    "content": "For on-call alerts, you want to strictly limit the amount of pages you send out in order to maintain a high signal-to-noise ratio. Every page interrupts the on-call engineer’s workflow, and in the worst case, it wakes him up at night. In order to do this, you want to alert on symptoms as far up the stack as possible, rather than causes. Instead of having an alert that says “one of our MySQL database servers is down”, you want “the website error rate went up”, which catches a huge number of potential issues, whereas a redundant database server going down may not have any impact whatsoever. Once you’ve been woken up, you can then use your detailed metrics and dashboards to narrow down the cause of the outage, but there’s no point on alerting on them unless they impact service quality. Exceptions to this are cases where you can reliably extrapolate that something is going to break soon - like “this disk will up in 30 minutes, and it will take down our service unless it’s fixed. Low-Severity Alerts . There are many conditions that need to be taken care of, just not immediately. Your redundant database server went down and nobody got paged - great! But, you still need someone to fix that database server, or clean up the log partition that will soon fill up, or refill your coffee maker (you’re monitoring your coffee maker, right? It’s critical infrastructure!). A common approach is to have a separate, low-severity notification channel that won’t wake anyone up, but still ensure that the issue is resolved. We recommend a channel in your favorite business messaging application, plus a dashboard which shows outstanding alerts (the dashboard is really important, since it ensures that alerts are acted upon - it’s basically a to-do list). ",
    "url": "/Concepts/Monitoring.html#symptoms-based-alerting",
    
    "relUrl": "/Concepts/Monitoring.html#symptoms-based-alerting"
  },"30": {
    "doc": "Monitoring",
    "title": "What To Monitor",
    "content": "There are two commonly used methodologies to determine a baseline of what to monitor - USE (utilization, saturation and errors) and RED (rate, errors and durations). USE is a general-purpose resource-centric view. Examples of resources are CPUs, disks and some software services that are effectively resources. Utilization . An average over a time interval of how much time your resource is busy vs. idle. A common example are CPU utilization values (90% busy), memory usage. Saturation . How much extra work is queued up/waiting. Common examples are the CPU load (processor run queue length), worker queue sizes, network interface queues or memory swapping. Errors . Accumulated number of error events like network interface error counters, queue overflows, application exceptions and restart counters. RED is a higher-level service-centric view for request-based services like APIs and webservers. Rate . The rate of work being completed, like requests per second for APIs and webservers, packets per second for network devices, or concurrent sessions for push notification servers. Errors . Number of requests that failed. Durations . How long single requests take to complete. Google’s SRE book has a slightly different approach (“The Four Golden Signals”) which combines both - latency (durations), traffic (rate), errors and saturation (saturation being more broadly defined as the utilization of a system’s bottleneck/constraint). Both methodologies complement each other and provide a comprehensive view of your applications performance. Take them as suggestions, not gospel - they don’t always fit. Make sure to understand how your application behaves and define custom metrics as you see fit. Here are examples of metrics we collect for our Cosmos validators: . | Network latencies between our different sites running our active-active validators (essential for troubleshooting high block signing latencies, since latency sets the lower bound for our internal consensus mechanism). | BGP path distance and ASN-vs-distance metrics between our different sites (unexpected changes in BGP paths can explain changes in latency and need to be investigated, since they can increase the risk of network partitions). | Metrics exposed by Tendermint . | Block height (consensus_height) | Total online weight in the network (consensus_validators_power) | Missing validators (consensus_missing_validators) | Byzantine validators and weight (consensus_byzantine_validators and consensus_byzantine_validators_power) | Last block size (consensus_block_size_bytes) | Current consensus round (consensus_rounds) | Number of peers (p2p_peers) | . | chain_exporter metrics . | Blocks that our validators missed (miss_infos table) | Recent proposals in the network (proposals table) | Our validator’s outbound peers (peer_infos table) | . | Golang process statistics (automatically generated by the Go Prometheus exporter) . | Process memory (process_resident_memory_bytes) | Go stack metrics (go_memstats_alloc_bytes) | Open file descriptors (process_open_fds - fds are a limited resource!) | Number of goroutines (go_goroutines - Goroutines aren’t OS threads, they’re limited by available memory and garbage collection costs; the metric is particularly important to spot Goroutine leaks which lead to high memory usage) | Garbage collector quantiles (go_gc_duration_seconds) | . | node_exporter metrics | . Of course, not all of them have alerts, but they’re displayed in our operational dashboards and are the first step in troubleshooting. Our testnet_deploy GitHub repo includes example dashboards for these metrics. ",
    "url": "/Concepts/Monitoring.html#what-to-monitor",
    
    "relUrl": "/Concepts/Monitoring.html#what-to-monitor"
  },"31": {
    "doc": "Monitoring",
    "title": "What To Alert",
    "content": "All alerts should be, fundamentally, rooted in your business goals. If you’re hosting an application, you usually have customers, and your customers expect a certain service level. The service level can be expressed in terms of application metrics - so-called service level indicators. You then define service level objectives (SLOs) - the bar you set for yourself - and probably service level agreements (SLAs) with your customers, usually lower than your SLOs. Chapter 4 of Google’s SRE book has a great writeup on how to define your service levels - we recommend you read it (along with the rest of that book). Todo . Coming soon . ",
    "url": "/Concepts/Monitoring.html#what-to-alert",
    
    "relUrl": "/Concepts/Monitoring.html#what-to-alert"
  },"32": {
    "doc": "Monitoring",
    "title": "How to Monitor",
    "content": "The only mature open-source implementation of metrics-based alerting is the Prometheus project. It serves as metrics collector, time-series database and alerting system. While Prometheus has a simple web UI for ad-hoc queries and debugging, Grafana (which includes a Prometheus data source out of the box) is commonly used for complex dashboards. Todo . Coming soon . Counters vs gauges . Todo . Coming soon . Quantiles . Todo . Coming soon . Push vs Pull . Todo . Coming soon . ",
    "url": "/Concepts/Monitoring.html#how-to-monitor",
    
    "relUrl": "/Concepts/Monitoring.html#how-to-monitor"
  },"33": {
    "doc": "Monitoring",
    "title": "How to Alert",
    "content": "Todo . Coming soon . ",
    "url": "/Concepts/Monitoring.html#how-to-alert",
    
    "relUrl": "/Concepts/Monitoring.html#how-to-alert"
  },"34": {
    "doc": "Monitoring",
    "title": "Events",
    "content": "Todo . Coming soon . ",
    "url": "/Concepts/Monitoring.html#events",
    
    "relUrl": "/Concepts/Monitoring.html#events"
  },"35": {
    "doc": "Monitoring",
    "title": "Further Reading",
    "content": "Recommended reads on this topic: . | Site Reliability Engineering by Google (Betsy Beyer, Chris Jones, Jennifer Petoff and Niall Richard Murphy). The systems reliability engineering bible. Its a great read in its entirety, but as far as monitoring and alerting are concerned, chapters 6 and 10 are must-reads. Read it online, Amazon . | My Philosophy on Alerting by Rob Ewaschuk. Precursor to Google’s SRE book and still a good and succinct read on its own. Read it online . | The USE Method, article by Brendan Gregg. Brendan Gregg is a well-known (if not the) expert on performance analytics. This article introduces the USE method. Read it online . | Systems Performance by Brendan Gregg. The reference book for systems performance analysis and optimization, with a focus on UNIX (Linux, Solaris) performance. Amazon (affiliate link taken from Brendan’s website) . | . ",
    "url": "/Concepts/Monitoring.html#further-reading",
    
    "relUrl": "/Concepts/Monitoring.html#further-reading"
  },"36": {
    "doc": "Monitoring",
    "title": "Monitoring",
    "content": " ",
    "url": "/Concepts/Monitoring.html",
    
    "relUrl": "/Concepts/Monitoring.html"
  },"37": {
    "doc": "Nix",
    "title": "Nix",
    "content": " ",
    "url": "/Tools/Nix%207784f9d6cc4e4d22b641606d10105fc4.html",
    
    "relUrl": "/Tools/Nix%207784f9d6cc4e4d22b641606d10105fc4.html"
  },"38": {
    "doc": "Nix",
    "title": "Overview",
    "content": "Nix is a tool that takes a unique approach in package management and enables a developer to have complete, declarative and reproducible builds. Using Nix allows all developer environments to be highly customized and reproducible making collaboration easier (no need to deal with slightly different environments, just add a shell.nix or flake.nix to your project) and/or to have greater control over the environment you are running a system in. Nix allows you to define everything in the system from volumes, security, networking, and packages in a single file. ",
    "url": "/Tools/Nix%207784f9d6cc4e4d22b641606d10105fc4.html#overview",
    
    "relUrl": "/Tools/Nix%207784f9d6cc4e4d22b641606d10105fc4.html#overview"
  },"39": {
    "doc": "Nix",
    "title": "Reading",
    "content": "List . ",
    "url": "/Tools/Nix%207784f9d6cc4e4d22b641606d10105fc4.html#reading",
    
    "relUrl": "/Tools/Nix%207784f9d6cc4e4d22b641606d10105fc4.html#reading"
  },"40": {
    "doc": "Peers",
    "title": "Tendermint P2P Layer",
    "content": "This article explains the Tendermint P2P Layer and many of its gotchas. Understanding the P2P Layer has been very important to us, since it has important systems architecture implications. ",
    "url": "/Concepts/Peers.html#tendermint-p2p-layer",
    
    "relUrl": "/Concepts/Peers.html#tendermint-p2p-layer"
  },"41": {
    "doc": "Peers",
    "title": "Intro",
    "content": "The Tendermint P2P implementation is based on a relatively simple concept. Types of peers . Each node in the network is configured to dial a set of seed and persistentPeers when it is first started. Both of these parameters can be set in the config. Persistent peers . The Tendermint node will try to maintain a permanent connection with this peer during its runtime. That also means that it will persistently try to redial the node if the connection fails. This is for example useful for the connection between Validator and Sentry nodes, because they will immediately try to reconnect after a connection failure, and there is no scenario where they could be stuck in a unreasonably long backoff or generally be removed from the peers addressbook which could cause unforeseen issues in a Sentry architecture. Seeds . Seed nodes are only there to provide an up-to-date list of peers of the network. If a node is configured to run as a seed node, it will actively search the network for new peers and store them in its addressbook. However, it will not maintain active connections with the peers it queries. Connections from a seed node are meant to be short-lived in order to just query the other peers addressbook, learn about its new peers and then disconnect again. If you specify a seed node in the config of your node it will try to dial it on startup to retrieve an up-to-date addressbook as well as a list of peers on the network to bootstrap its connections. Addressbook . From the moment the node has acquired a list of peers on the network it will store them in a weighted addressbook. This addressbook stores all peers the client has ever learned about (and possibly connected to). When a connection to a peer fails, this is marked in the addressbook and will lead to a backoff before the next reconnection attempt is made. If a peer connection fails for more than x times (where x is a constant hardcoded in Tendermint at the moment), the peer is marked as bad and removed from the addressbook. Connection Types . Inbound connection . Every connection that was initiated by another peer which contacted our node from the outside is called an inbound connection. The number of maximum inbound connections can be specified with max_num_inbound_peers. In order for another peer to create a connection to our node our P2P port (26656 by default) has to be publicly exposed. Outbound connection . Every connection that was initiated by our peer (because of persistent peers, manual dialing or the PEX reactor) is an outbound connection. In order to establish an outbound connection the P2P port does not have to be opened as long as outbound connections are allowed by firewall rules. ",
    "url": "/Concepts/Peers.html#intro",
    
    "relUrl": "/Concepts/Peers.html#intro"
  },"42": {
    "doc": "Peers",
    "title": "The peer reactor",
    "content": "Depending on whether you have a normal or seed node, the PEX (peer exchange) reactor will execute the following loop regularly. Normal peer . Startup . The node will check its addressbook for valid peers to connect to and connect to all of the persistent peers specified. If the addressbook is empty, it will try to connect to one of the specified seed nodes. Loop . In the peer exchange routine the node will try to connect to new nodes from its addressbook until it has reached the max_num_outbound_peers (as of tendermint commit 6fad8eaf5). It will also query a random peer for its addressbook if the addressbook of itself is not yet “full” (currently 1000 entries). Seed node . Startup . as with a normal node . Loop . The node will try to clean up its connections by closing every connection that has been found to be healthy. Then, it will attempt to connect to all its known peers from the addressbook and ask them for their addressbook. This behaviour intends to get a picture of the network that contains almost every public node available in order to allow new nodes to easily bootstrap using an up-to-date addressbook. ",
    "url": "/Concepts/Peers.html#the-peer-reactor",
    
    "relUrl": "/Concepts/Peers.html#the-peer-reactor"
  },"43": {
    "doc": "Peers",
    "title": "Operation Notes",
    "content": "Knowing all of this, there are a number of different ways to improve your network’s resilience by taking advantage of how the P2P reactor works. Running outbound only nodes . In order to reduce your DDoS attack surface you might want to run outbound only sentry nodes. Outbound only nodes behind a stateful firewall - that is, any firewall that isn’t a simple router ACL - allow you to completely drop incoming connections, permitting only packets belonging to existing sessions. That way, your node is not publicly reachable from the internet except for the TCP sessions that you have established with your peers. This greatly reduces the attack surface for network-layer attacks. Depending on your peer selection policy, it can also reduce the attack surface for L7 (application layer) attacks by only connecting to trusted nodes. With global TCP load balancers like Google Cloud and CloudFlare Spectrum, the stateful firewall is moved closer to the providers edge points of presence (PoPs), allowing you to absorb large denial-of-service attacks (the provider will drop unknown packets right when they enter their network, distributing attack traffic across their PoPs rather than congesting the single availability zone your application is running in). Additional safety measures could be to announce a wrong IP using PEX, which confuses nodes other than those those you are connecting to. That way, only the peers you have established connections with will know your true IP. However, this also increases the importance of having uncompromised peers because other peers of potentially good actors on the network won’t be able to connect to you and if your maximum number of outbound peers is filled with compromised peers, you will only see these nodes and no others as we have learned above. Such a compromise may allow an attacker to alter your view of the network, rendering you unable to catch up with the network or even cause your node to exhibit byzantine behaviour, if it’s in a vulnerable state. So it’s very important to (either): . | Set a high number of outgoing peers | Add at least some trusted persistent peers | Implement additional measures to either select peers or rotate peers on a regular basis | . Warning . If your firewall is misconfigured or you are announcing a wrong public IP (e.g. your internal Docker IP) your node will be outbound-only unintentionally since no other nodes can connect from the outside (assuming you are not configured as persistent peer using your true IP). This can result in slow syncing and missed blocks due to delays in consensus message gossip, unless you apply the optimizations noted above. Note . Outbound-only peers are meant as an additional measure to protect your validator from DDoS and similar attacks. However, running only outbound peers can cause network partitioning, slow bootstrapping for new network participants and general network destabilization. Plase make sure that you run only a small portion of your sentries in an outbound-only configuration to ensure the overall quality of the network. Running “full-duplex” nodes . Full-Duplex or inbound/outbound nodes are the default configuration for nodes. They allow both inbound connections to be established from the outside as well as outbound connections. In order to run a full-duplex node your firewall needs to be opened for both in- and outbound traffic on the relevant port (26656 by default). Since the host can be reached from the public internet, the risk for DDoS is higher. However, this configuration allows new peers to establish connections with them and thereby increases the overall network’s resilience. You should run most of your sentries as “full-duplex” nodes. Please keep in mind to set your number of maximum inbound peers in the config file to an appropriate value to get a better view of the network. Private nodes . Private nodes communicate via VPN or other private networks and allow only selected peers to establish connections with them. Such a configuration could be used for validator-validator private peerings. In order to not leak any information about the node, it can be run with PEX disabled and the peering with the other nodes hardcoded as persistent peer. ",
    "url": "/Concepts/Peers.html#operation-notes",
    
    "relUrl": "/Concepts/Peers.html#operation-notes"
  },"44": {
    "doc": "Peers",
    "title": "The Sentry architecture",
    "content": "In order to deploy multiple different kinds of nodes, as described above, in our network and combine their strengths we need an additional layer besides our single validator node (or multiple validator nodes). In order to effectively mitigate DDoS attacks we also don’t want to publicly expose our validator nodes (IPs) to the internet. This is implemented in an architecture developed by the Tendermint/Cosmos team called Sentry node architecture. While the validators reside in a Virtual Private Network (like it’s e.g. offered by many cloud providers) or actual private network that is disconnected from the internet our Sentries basically build a proxy layer between this network and the public internet / cosmos network. Sentry nodes are full cosmos nodes whose only task it is to relay messages and blocks to the validator nodes. This is done by assigning the Sentry nodes both a public and private interface and hardcoding the validator nodes as persistent peers. The PEX reactor is limited in a way to not broadcast the validator nodes to the other public peers in the network. As a result no network participant will ever have a direct connection with one of our validator nodes and will therefore also not be able to DDoS these directly. The Sentry nodes form a shielding layer and are not limited in their number since they only act as a proxy and have no special stateful task like signing. New nodes can be added and removed at any time as long as a minimum amount is kept online. To learn more about the Sentry architecture and how to configure your nodes accordingly look at the Cosmos Docs. ",
    "url": "/Concepts/Peers.html#the-sentry-architecture",
    
    "relUrl": "/Concepts/Peers.html#the-sentry-architecture"
  },"45": {
    "doc": "Peers",
    "title": "Sentry-Auto-Scaling",
    "content": "Actually… Sentry Auto Scaling isn’t the best way to protect yourself against DDoS attacks, and Certus One is investing in proper DDoS protection rather than sentry scale-out. Autoscaling is a common and successful defense against application-layer DDoS in webservers and APIs - you just outnumber the attacker by responding to every single of their requests. It might seem obvious to apply the same approach to sentry nodes, however, it’s less effective and more expensive than you might expect. Let’s first take a look at potential DDoS vectors of your validator: . L7 - Application Layer: . Vulnerabilities in Tendermint or the Cosmos SDK can allow an attacker to slow or take your nodes down with little effort and bandwidth. Traditional DDoS solutions will mostly not be able to mitigate this since they lack protocol-level insight. L4 - Protocol Layer: . SYN floods and similar attacks which aim to overwhelm your load balancer or operating system or fill up its flow tracking tables. L2/3 - Network Layer . Large-scale high-bandwidth reflection attacks which aim to saturate the network interface of your hosts, or provider, or even your provider’s provider (it happens). Now, how does autoscaling mitigate these? . L7 attacks cannot be mitigated by creating more nodes. Since there are no high bandwidth requirements on the attacker side, they can just continue attacking each new node, taking it down as well which would trigger the creation of more new nodes in an auto-scaling environment. It’s not much of a difference to them whether they need to attack 100 or 200 nodes, but it makes a huge difference to you. It won’t get you anywhere, but will get really expensive, really fast (which might be all the attacker wants, anyway). To prevent this, one would need sophisticated auto-scaling algorithms which stops scaling up if new nodes quickly stop responding. So what about L2/3/4 attacks? . If your sentry nodes are getting attacked by large amplification attacks (which are easily in the &gt;100 Gpbs range), they will be down immediately - all it takes is 1-2 Gbits. Your provider is probably going to nullroute your IP, preventing the attacker from taking down the provider’s network, sacrificing your IP for the greater good. On the other hand, if your provider is experienced in mitigating DDoS attacks and has sufficient bandwidth, he will easily be able to mitigate the attacks. They are straight-forward to filter (fixed source port). The same goes for SYN floods - they either kill your node right away, or are easily defeated or rate limited to insignificance by a competent provider or even a cloud provider’s TCP proxy (see above - GCP and CloudFlare can both proxy TCP connections). Auto scaling of sentries can help with volumetric attacks, as you would just spawn more sentries until the attacker no longer has sufficient capacities to attack all of them. The issue is that this requires a lot of resources on your side. Spawning up nodes to match the bandwidth of the attacker can be quite expensive, especially over longer periods of time. While you might remain online during the attack, the attacker is still having the financial upper hand and could potentially blackmail you (he’s not paying for the compromised servers he’s using!). In order to quickly scale up Cosmos nodes you need to have snapshots of the blockchain data in place because it would otherwise take very long for it to sync with the network. That is another point of failure in case of such an attack especially considering the growing size of the blockchain and the extra infrastructure you need. Additionally, even with recent snapshots, it will take a while for you new node to catch up. What else to do? . One of the very obvious alternatives and additional security measures is outbound-only nodes as described above, in combination with a global TCP proxy like GCP’s global LB or CloudFlare Spectrum. These can handle bandwidths in excess of most realistic DDoS attacks, without any of the traffic reaching your sentry node. Additionally, chances are that your attacker do not even know the IP address of the node since it only initiates a limited amount of outbound connections. This can even be stripped down to a selected set of peers to further increase security which ultimately leads us to private peers. With private peers in place, you have got nodes that are not publicly known and in the best case (with potential direct in-cloud peerings or private network interconnects) expose almost no external attack surface. An attacker would have to take down all of the other validators you peer with to prevent them from relaying your messages. This eliminates most of the DDoS threat - an attacker would have to overwhelm Google’s TCP proxy or CloudFlare spectrum as well as all of your private peers. If he even misses a single node, your validator will still be functional. We recommend you invest your time into advanced DDoS mitigation setups, good relationships with other validators and a diverse set of sentries running at different providers rather than building a less effective, but complex cloud autoscaling mechanism. ",
    "url": "/Concepts/Peers.html#sentry-auto-scaling",
    
    "relUrl": "/Concepts/Peers.html#sentry-auto-scaling"
  },"46": {
    "doc": "Peers",
    "title": "Peers",
    "content": " ",
    "url": "/Concepts/Peers.html",
    
    "relUrl": "/Concepts/Peers.html"
  },"47": {
    "doc": "Security Engineering",
    "title": "Security Engineering",
    "content": "Someone once said that, paraphrasing: . While most of systems engineering is about making computers do things, security is just about the opposite - keep your computers from doing anything else. While much of the public focus on security engineering is about the low-level technical details - finding and exploiting bugs, cryptographic algorithms, code signing, chains of trust, and so on, these - while important - are only one piece of the puzzle. Some of the hardest parts of security in most companies are actually not of the technical nature - from an academic point of view, most everyday security problems are downright boring - but making trade-offs, assessing risks, understanding your adversaries, and writing procedures, policies and checklists (also boring, both academically and practically). Not every company needs a team of world-class security carrying out original research (though it certainly helps), but every company needs to understand their risks and plan accordingly. That’s not to say that the technology isn’t important - quite the opposite. Validators, in particular, operate at a pretty low level, cryptographically speaking, and do need to understand the cryptographic primitives that they’re using, especially if they build their own HSM integrations and similar pieces of security-critical code. Cutting-edge security technology makes risk mitigation much easier and can dramatically reduce costs. However, even the best security technology will fail if it’s not supported by a proper business framework. Most security failures are not due to clever attackers discovering a complicated timing attack in your HMAC algorithm or exfiltrating data by modulating your system bus, but dumb mistakes, human error in general and policy failures. Remember the Equifax breach? They failed to mitigate a vulnerability that had been publicly known for months. Their fancy IDS which detected the breach had been turned off because the CSO thought the alerts were too noisy. Those were management failures. Unfortunately, this is how most breaches happen, and - barring the occasional smart contract troubles - blockchain companies make no exception. Most blue team security measures can be (roughly) categorized into these three disciplines: . | Prevention - properly hardening your systems and organization to prevent incidents from happening in the first place, just like sturdy walls and secure locks are the best defense against burglary, it’s hard to overstate how important proper systems design is for security. Most security issues are mundane and easily prevented. | Detection - like with a good home alarm system, detecting an incident is the next best thing after preventing it. Studies say that the vast majority of attacks go on undetected for months until they’re discovered, often due to a mistake on the attacker’s part. | Response - properly responding to a security incident in an art in itself and can dramatically alter the outcome. Compromises are inevitable, and you need to be able to competently deal with them as they happen. | . The reality is that any sufficiently large network will have some compromised nodes at any given time, at the very least due to sheer scale and laws of probability (with a pinch of organizational incompetence inherent in large organizations sprinkled on top). It’s a common opinion that we have collectively failed at both incident prevention and detection and are now living in the age of incident response. However, at the scale of a typical validator operation, minimizing risks by achieving excellence at all three disciplines is both possible and reasonable. There’s - quite literally - a lot at stake, and a single compromise can easily kill a validator company. ",
    "url": "/Concepts/Security%20Engineering.html",
    
    "relUrl": "/Concepts/Security%20Engineering.html"
  },"48": {
    "doc": "Security Engineering",
    "title": "Single Sign On and 2FA",
    "content": "You need a secure single-sign on system. Unless you’re a large company who can afford to run and maintain their own SSO system, you should use Google’s GSuite. Enforce two-factor authentication for all users. You should use two U2F tokens per user (they’re the only kind of 2FA authentication that can’t be phished). Do not use SMS authentication - mobile phone providers are [un]surprisingly easy to social engineer into sending a replacement SIM card to someone else. Shared passwords are evil. Only ever use shared passwords as a last resort. Certus One has so far gotten away without a single shared password! Many third party suppliers support multiple user accounts - create an individual account for each team member. Have a company wifi router? Either use WPA2 Enterprise, or treat it like a public hotspot. Keep track of all shared passwords and be diligent about changing all of them when a team member leaves who had access to them, and deleting accounts at third parties. If an application does not support SSO login, much of the time, you can use oauth2_proxy or keycloak-gatekeeper as authenticating reverse proxies. ",
    "url": "/Concepts/Security%20Engineering.html#single-sign-on-and-2fa",
    
    "relUrl": "/Concepts/Security%20Engineering.html#single-sign-on-and-2fa"
  },"49": {
    "doc": "Systemd",
    "title": "Systemd",
    "content": "Used to manage all processes for a consistent, flexible, configurable approach . Resources . systemd for Administrators, Part XVIII . ",
    "url": "/Tools/Systemd%2052d24727df354933a92435c35b657813.html",
    
    "relUrl": "/Tools/Systemd%2052d24727df354933a92435c35b657813.html"
  },"50": {
    "doc": "Systems Design",
    "title": "Systems Design",
    "content": "The key to building and maintaining highly secure and reliable systems is simplicity - a good system will have nothing to take away, rather than nothing to add. Each component you use you will have to secure, update and debug forever. Like open source projects which reject code not because it’s bad, but because they don’t have sufficient capacaties to maintain it, you need to be very careful about each piece of technology you introduce into your stack and carefully weight its benefits against the extra complexity it introduces. Debugging and securing a system is an order of magnitude more complicated than building it. There’s a common saying that if you build the most clever system you can think of, you’re by definition unqualified to maintain it - and there’s a lot of truth to it. ",
    "url": "/Concepts/Systems%20Design.html",
    
    "relUrl": "/Concepts/Systems%20Design.html"
  },"51": {
    "doc": "Systems Design",
    "title": "Why not Kubernetes?",
    "content": "We’ve heard about many validators who plan to use Kubernetes for their production setups. We strongly recommend against the use of Kubernetes and similar technologies for your core validator operations - they solve problems validator operators don’t have. Validator core infrastructure are pets, not cattle. You can’t just deploy a cloud instance, you need to rent dedicated servers and plug HSMs into them. Even if you’re running an active-active setup like ours which tolerates full node outages, you’re unlikely to gain enough from Kubernetes to justify its costs. We recommend traditional configuration management tools like Ansible. Even plain Docker usage should be carefully evaluated - while Docker itself is quite stable, even in 2018, the overlay filesystems and namespacing technology it uses haven’t stabilized yet (not for lack of trying, but any complicated piece of code in the kernel needs decades to mature; people are still finding bugs in ext4 to this day). Any large-scale production user of either Docker and Kubernetes will have tales of Docker daemon crashes in production, weird kernel issues that required node reboots and scheduler bugs that required them to read the Kubernetes source code at 3am in the morning. This is perfectly fine for the kind of stateless infrastructure Docker and Kubernetes are designed for - they are built to tolerate single node losses, or build systems. In fact, many production deployments can auto-update and reboot cluster nodes (like CoreOS/Container Linux does). However, none of this applies to core validator infrastructure. cosmos-sdk compiles to a single binary, you don’t need Docker to deploy it (it’s quite useful for building it, though). You’re not going to need to scale your validator setup up and down across a fleet of thousands of machines. Being able to list all processes running on your nodes and knowing exactly what they’re doing is beautiful, and while it’s certainly possible with Kubernetes, it’s a lot easier with with a stripped-down, hardened node running nothing but your validator software. Advanced security setups like eBPF seccomp policies, auditing, SELinux policies and just plain debugging get a lot easier when there are no kernel namespaces, Docker daemons, runC wrappers and overlay filesystems to reason about. Both Docker and Kubernetes also add a lot of unnecessary attack surface (properly securing Kubernetes alone is pretty complicated - it’s a REST API which hands out omnipotent tokens which have root access to your nodes - that’s the opposite of defense in depth!). Certus One has extensive experience using Docker, Kubernetes and Red Hat’s OpenShift k8s distribution in production and we’re confident that we could pull it off, just like we have no doubt that other teams will. However, we believe that a better result can be achieved without, with time better spent on security hardening and tooling. That being said, we do use Kubernetes for our auxiliary infrastructure like our monitoring stack, continous integration, testing setup and various other internal infrastructure needs. It’s perfect for that - our monitoring stack in particular consists of many small services talking to each other, and Kubernetes is perfect for that. We just don’t want it anywhere where its failure would affect the core of our business - running secure validators. ",
    "url": "/Concepts/Systems%20Design.html#why-not-kubernetes",
    
    "relUrl": "/Concepts/Systems%20Design.html#why-not-kubernetes"
  },"52": {
    "doc": "Systems Design",
    "title": "Network topology",
    "content": "We recommend a flat network topology where each node has its own unique IP address, with full end-to-end connectivity (only hindered by your firewall rules). You should prefer a fully routed L3 topology over switched L2 topologies, especially those of the “magic SDN” variety which use a separate control plane (like OpenVSwitch, ZeroTier and most datacenter SDN technologies in general). L2 topologies have no advantage over L3 routing for applications that have no special networking requirements. Their main users are service providers which need to span L2 network across their data centers to provide their customers with virtual networks. For everyone else, L3 networks are the better choice. L2 networks are brittle, hard to segment (they’re basically one large failure domain), and hard to debug. L3 networks are built to scale, have well-defined interfaces and control plane protocols, and great troubleshooting tools (routing tables, traceroutes and BGP are more intuitive than an opaque SDN control plane which pretends to be a gigantic flat L2 network, but isn’t). The potential blast radius in a L3 network is much smaller than in a L2 network, where a stray spanning-tree packet can potentially take down an entire network. For example, a GCE VPC is completely routed. Each virtual machine has its own transfer network with the VPC router, and the only broadcast packet you’ll ever see are the ones sent by either the router, or the instance. The VPC router maintains a /32 route for each VMs IP addresses. This is why you can’t set next hop routes in your virtual machines, but need to add them in the VPCs routing table - while it pretends to be a large /24 network, it’s in fact a routed network where each instance has its own little network. Via VPC peerings, you can connect multiple networks to their respective IP ranges, which is “just” another entry in the VPC routing table pointing to the other VPC’s router. Network address translation is best avoided. It adds an extra layer of complexity, makes it harder to attribute traffic once it left a NAT boundary and is another state machine on top of TCP and Tendermint’s consensus protocols. It creates all sorts of operational headaches - you need to maintain a separate list of public/private IPs and port forwardings, you can’t easily whitelist traffic from single nodes once it crossed a NAT boundary (you would need to log NAT source ports), and so on. NAT is not a security tool, firewalls are. You can achieve the same level of network isolation with and without NAT. It’s hard to avoid - most cloud provider’s VPC networks use RFC 1918 addresses internally with NAT for external connectivity, and you need some sort of NAT at the network edges - but you should keep its use to a minimum and ensure that nodes can communicate without NAT inside of your network. Kubernetes is another good example - each pod has its own IP address in a large flat network, which can be either routed or switched, depending on the network plugin you use - Calico is what we use. Each pod can talk to each other across this flat network as long as the network policy allows it. However, pods need to talk to the outside world sometimes, so each node does outgoing NAT for the traffic originating from pods running on it. The outside world also needs to talk to some of the services running in the cluster, so there’s a load balancer which accepts traffic on its public IP address and load balances it to the internal IPs. ",
    "url": "/Concepts/Systems%20Design.html#network-topology",
    
    "relUrl": "/Concepts/Systems%20Design.html#network-topology"
  },"53": {
    "doc": "Systems Design",
    "title": "Secret management",
    "content": "Avoid working with secrets, especially bearer tokens, especially if they can be used on public APIs without any additional layer of security (looking at you, public cloud platforms and k8s). Use service-level certificate-based authentication to authenticate your services against a centralized secrets storage like Hashicorp Vault. If possible, use Vault’s auto-provisioning feature which creates individual short-lived credentials for each service. If you use stateless tokens like JWT, make sure to hardcode the signature algorithm and either use very short-lived tokens that expire after a few minutes, with stateful refresh tokens that you can invalidate, or another invalidation mechanism like revocation lists or a mechanism that invalidates all tokens issued before a certain timestamp (for emergencies). Red Hat IDP/Keycloak is a good OAuth/JWT server which implements both short-lived tokens as well as not-before timestamps. If you have a lot of services that need to authenticate at each other, you might reach a point where a service mesh like Istio is worth looking into. ",
    "url": "/Concepts/Systems%20Design.html#secret-management",
    
    "relUrl": "/Concepts/Systems%20Design.html#secret-management"
  },"54": {
    "doc": "Tailscale",
    "title": "Tailscale",
    "content": " ",
    "url": "/Tools/Tailscale%20db8b7f2df4aa4d2e81cf9137b3ea7dfe.html",
    
    "relUrl": "/Tools/Tailscale%20db8b7f2df4aa4d2e81cf9137b3ea7dfe.html"
  },"55": {
    "doc": "Terraform",
    "title": "Terraform",
    "content": "Overview . Terraform is a an infrastructure as code solution that allows you to provision, change, and version and resource in any cloud environment. Some common use cases for terraform are . | Writing infrastructure as code to automate the provisioning of your services. | Usage for a multi cloud deployment | Managing a kubernetes setup | Easily manage network infrastructure | . Terraform allows small teams to work fast and scale quickly. Having all of your infrastructure managed by a set of reproducible code, you can quickly manage your deployments without the need for dedicated devops or infrastructure engineers. 💡 If you are looking for “infrastructure as code” for bare metal machines you might want to look into [flatcar](https://flatcar-linux.org), [coreos](https://getfedora.org/en/coreos?stream=stable), [pxeboot](https://en.wikipedia.org/wiki/Preboot_Execution_Environment), or [MasS](https://maas.io) Terraform CLI . The terraform cli is pretty straightforward, and documentation can be found here . | [Basic CLI Features | Terraform by HashiCorp](https://www.terraform.io/cli/commands) | . One of the most useful functions of the cli is that if you are connected to a terraform cloud backend you can switch workspaces. This allows you to use the same provisioning code for many (even slightly different) projects. Without workspaces you generally would be overwriting current resources. A workspace can be configured like so . terraform { required_providers { aws = { source = \"hashicorp/aws\" version = \"~&gt; 4.0\" } } backend \"remote\" { organization = \"adajcentresearch\" hostname = \"app.terraform.io\" workspaces { prefix = \"adjacent-\" } } } . Terraform Cloud . Cloud manages all remote builds along with maintaining a compete overview of al infrastructure deployed under the organization. | [Terraform | HashiCorp Cloud Platform](https://cloud.hashicorp.com/products/terraform) | . Examples . Examples of a terraform deployment with NixOS can be found below . | https://github.com/adjacentresearchxyz/deployment | https://github.com/adjacentresearchxyz/solana-deployment | . Reading . List . ",
    "url": "/Tools/Terraform%205bdc9ddd7b2342e6b67b83d866006fd6.html",
    
    "relUrl": "/Tools/Terraform%205bdc9ddd7b2342e6b67b83d866006fd6.html"
  },"56": {
    "doc": "Testing",
    "title": "Testing your tooling¶",
    "content": "It is really important to test changes to your internal tooling as well as your processes in an environment closely resembling your production setup. The public gaia testnets can be a good place to become familiar with the basics, but most of the time, you need greater levels of control over the testing environment than a public testnet can provide (like a network with byzantine validators, network partitions, packet reordering or loss). Certus One has built a full, one-click deployable testnet setup which also includes a complete monitoring stack. The system built on OpenShift Origin / Kubernetes allows you to spin up a fresh Cosmos testnet with n nodes/validators within seconds. Our largest single-node testnet had 400 validators and minted millions of blocks before eventually running out of disk space. This allows you to deploy your tools network, iterate on them and run tests in a high-speed network - by default, the validators are configured to skip the timeout and produce blocks as fast as possible. You can also simulate special network conditions like double signing by spawning a second instance of a validator or any other scenario. You have got full control and if something goes wrong you can simply spin up a new network. Our use of Kubernetes makes our testnet easily extensible and scalable. ",
    "url": "/Concepts/Testing.html#testing-your-tooling",
    
    "relUrl": "/Concepts/Testing.html#testing-your-tooling"
  },"57": {
    "doc": "Testing",
    "title": "Case Study at Certus One",
    "content": "At Certus One, the Kubernetes testnet has dramatically simplified the integration testing of our JANUS active/active validator technology. We are spinning up a custom testnet with JANUS [1] and Aiakos [2] right from our internal CI pipeline, allowing us to quickly spot regressions. This has significantly improved the speed at which we can iterate on our software, while being confident not to break our production environment. It also allows to test new dashboards and alerts to elimiate false posives or negative before we deploy to production. We keep our testnet very close to production, such that every production component is present to be tested and experimented with. Due to the nature of it being built on Kubernetes, it also allows to easily deploy it on several cloud providers as well as bare metal to evaluate performance. Adding new components is as simple as adding a few lines of Kubernetes deployment config. ",
    "url": "/Concepts/Testing.html#case-study-at-certus-one",
    
    "relUrl": "/Concepts/Testing.html#case-study-at-certus-one"
  },"58": {
    "doc": "Testing",
    "title": "How to deploy",
    "content": "The source code for the public version of our testnet deployment can be found here: Testnet Github . We have also prepared a video with setup instructions which will also guide you through the features of the setup. Before watching, you have to setup a Openshift Origin cluster using OpenShift’s documentation or our README. ",
    "url": "/Concepts/Testing.html#how-to-deploy",
    
    "relUrl": "/Concepts/Testing.html#how-to-deploy"
  },"59": {
    "doc": "Testing",
    "title": "Testing",
    "content": " ",
    "url": "/Concepts/Testing.html",
    
    "relUrl": "/Concepts/Testing.html"
  },"60": {
    "doc": "High Availability",
    "title": "Validator High-Availability",
    "content": "Tendermint is a globally consistent, byzantine-fault tolerant consensus-based replicated state machine - the gold standard in distributed systems. A single validator, however, is not highly available. It doesn’t need to be - the network tolerates single validator failures just fine. However, as the validator operator, things look different and your tolerance for single validator failures is pretty low. Sooner or later, every validator operator is confronted with the question of making their validator fault-tolerant. Unfortunately, there’s no established procedure for this and each team is forced to build their own high availability solution. This article portrays some possible HA topologies and their pros and cons. Running a Tendermint validator is - like any distributed system - a delicate balance between ensuring availability and consistency/correctness (availability as in “up and signing blocks”, and consistency as in “no byzantine behavior”). As is well known, the CAP theorem states that you can only pick two of partition tolerance, consistency and availability. Since network partitions are inevitable in any distributed system, you can’t pick CA, and the only choices are AP and CP. With Cosmos validators, the penalty for inconsistency (double signing!) is much harsher than unavailability (you even get a few minutes to fix it before you are slashed). This means that the only reasonable choice is a CP system - if there’s even the slightest possibility that more than one node is active at the same time, it needs to sacrifice availability (i.e. stop signing). ",
    "url": "/Concepts/Validator%20High%20Availability.html#validator-high-availability",
    
    "relUrl": "/Concepts/Validator%20High%20Availability.html#validator-high-availability"
  },"61": {
    "doc": "High Availability",
    "title": "Single Node Validator",
    "content": "Since inconsistency is so dangerous, running a single-node validator is a very reasonable choice. Modern datacenter hardware, in a modern datacenter, with redundant networking, designed by an experienced systems architect, has a very low failure rate sufficient for many low-stakes validators. As any sysadmin will tell you, badly designed high availability setups tend to fail at a much higher frequency than reliable single-node ones. By never running two nodes at the same time, the risk of double signing is very low - one would have to trick your replacement validator into signing an earlier block while it recovers or exploit a vulnerability in Tendermint. However, if the hardware or datacenter does fail in a catastropic way, you will be down for an extended period of time until you have got replacement hardware in place and re-synced. While acceptable for low-stakes validators, most commercial validator operations won’t be able to accept this risk. Even redundant power and networking setups have a non-zero chance of failure, in fact, most systems aren’t fully isolated and failures often tend to be correlated. (True story: your router has redundant PSUs? Oops, both fans just simultaneously ingested a packaging foil that someone left in the rack). ",
    "url": "/Concepts/Validator%20High%20Availability.html#single-node-validator",
    
    "relUrl": "/Concepts/Validator%20High%20Availability.html#single-node-validator"
  },"62": {
    "doc": "High Availability",
    "title": "Active-Standby Validator",
    "content": "The next obvious step following a single-node validator is an active-standby setup with manually promoted slaves. If the active node dies, a sysadmin gets paged, ensures the active node is actually dead, and then manually promotes the standby node. You would be surprised how many large SaaS businesses rely on a single beefy MySQL or Postgres server with manual failover! . Both nodes would be identically configured, with the same validator key, mnode key and moniker. This requires an on-call rotation with very low response times, which is expensive - you’re basically paying someone to sit at home all week, ready to react within minutes (most companies which do this do a follow-the-sun rotation with offices on three continents). It’s also susceptible to human error in determining node states. Fortunately, active-standby setups are very common and there’s a lot of tooling for automated failover. The state-of-the art solution is Pacemaker/Corosync, superseding heartbeat. Both were initially designed for VM clusters, which have very similar requirements to validators: no VM may ever run twice on the cluster, since it would result in immediate data corruption with both running from the same storage. While Pacemaker/Corosync supports running with only two nodes, this is essentially a CA setup and will not survive a network partition. This is common (and reasonable) for router/firewall clusters, with devices close to each other and redundant network interfaces and cabling, but we do not recommend a two-node cluster for validators due to the obvious risks e.g. of reaching a split-brain scenario where both nodes go active at the same time. Best practice for Pacemaker is a three node deployment - one active node, one standby node and a third quorum-only/witness node. Pacemaker will only enable a resource (i.e. start the validator service) if it can establish a quorum, and will self-fence (i.e. kill the validator service; the act of reliably excluding a broken node from the cluster is called fencing) if it loses quorum. However, even with a quorum, self-fencing can fail. There are many edge cases around the interaction between pacemaker and the resources it protects. For instance, if pacemaker crashes, the node might be considered dead, but the validator service is still running, or your system’s service manager reporting the validator service as down when it’s actually still running. To prevent these cases, a so-called fencing device like a mechanical relay or out-of-band management interface (IPMI, iLO, …) is necessary which interrupts power for the other node to ensure that it’s really really down (also called STONITH - “shoot the other node in the head”). A Pacemaker/Corosync is a good option for validator high availability, but involves risks and drawbacks: . | Pacemaker/Corosync is complicated to operate and has many edge cases. We recommend reading the Red Hat guide linked above which details common Pacemaker setups, and hiring someone who has experience with Pacemaker in critical production environments. | Fencing is failure-prone - it’s actually really hard to ensure a node is down and won’t ever switch back on, either by resetting spontaneously or by operator mistake, and the fencing mechanisms needs to be tested extensively to reduce chance of failure. | Fencing and failover based on network load balancers or IP failover are unlikely to work as expected due to stateful connections and the P2P nature of the Tendermint network. You need to ensure that the actual processes (and ideally the physical hosts) are stopped. | You need to synchronize block height/round/step of the last signature to your standby node or risk double signing due to a race condition during failover or someone tricking your node. Do not use shared or replicated storage - it’s hard to reason about and introduces an additional point of failure (see our response in this forum thread). | Pacemaker/Corosync aren’t designed to work across high latency networks, so this setup won’t scale beyond a single data center or even metro network (the corosync protocol expects latencies &lt;2ms). | . ",
    "url": "/Concepts/Validator%20High%20Availability.html#active-standby-validator",
    
    "relUrl": "/Concepts/Validator%20High%20Availability.html#active-standby-validator"
  },"63": {
    "doc": "High Availability",
    "title": "Active-Active Validator",
    "content": "Certus One has settled for an active-active validator setup. We run multiple validators, with the same key, at the same time, in multiple geographically distributed data centers. We built our own Raft-based consensus layer on top of the Tendermint core by implementing our own PrivValidator wrapper, which forces all signatures through a full Raft consensus. While we’ve seen some proposals [1] [2] to use the Tendermint protocol itself to provide consensus, we decided it would introduce unnecessary complexity where a (comparably) simple protocol like Raft would suffice - we fortunately don’t need byzantine fault tolerance here. This removes the brittleness of active-passive setups and the synchrony requirements of the corosync protocol. All of our validators are synchronized with the network at the current block height, ready to sign, while reliably preventing double signing through the Raft log. This provides guaranteed consistency as well as very high availability (the CAP theorem still wins, though - there’s a small window of time where a node can crash just before submitting a signature to the network, where we cannot reliably retry the operation since we can’t know for sure whether it succeeded; this is deliberate and cannot be fixed without risking consistency). While our active-active technology - called JANUS - currently isn’t an open source project, we open-sourced all of its dependencies and the testing framework [3] we use. We’re closely following upstream discussions and may decide to open source JANUS later. We believe that active-active validator setups are the best way going forward, and look forward to contribute to the community discussions regarding active-active setups. [1] . https://github.com/tendermint/tendermint/issues/1758 . [2] . https://github.com/tendermint/kms/issues/29 . [3] . Testing your tooling . Network topology . Raft is usually deployed within a single data center, however, the protocol does not require low latencies and works just fine with higher latencies (at the expense of elections and consensus read/writes taking a multiple of the worst latency in the cluster), assuming proper tuning and timeouts. The acceptable latency depends on the block times in the Tendermint network. We’re running all nodes within central Europe with no node being farther away than 50ms to ensure that a consensus read completes within &lt;1s. We run at most one validator per data center, with no more than n validators per autonomous system, where n is the number of nodes that the cluster can lose without losing consensus. All nodes are BGP multi-homed with multiple transit providers. We mapped out all routes between the data centers and ensured - through either private peering agreements or BGP traffic engineering - that even failure of critical transit networks or internet exchanges will not result in loss of consensus. This allows us to survive the failure of multiple data centers, whole autonomous systems, as well as internet exchanges while at most losing one block. ",
    "url": "/Concepts/Validator%20High%20Availability.html#active-active-validator",
    
    "relUrl": "/Concepts/Validator%20High%20Availability.html#active-active-validator"
  },"64": {
    "doc": "High Availability",
    "title": "High Availability",
    "content": " ",
    "url": "/Concepts/Validator%20High%20Availability.html",
    
    "relUrl": "/Concepts/Validator%20High%20Availability.html"
  },"65": {
    "doc": "Validator Operations",
    "title": "Validator Operations Guide",
    "content": "Running a proof-of-stake validator puts a much greater emphasis on technical correctness, sound systems architecture, security, and overall operational excellence than most distributed systems. In a proof-of-stake cryptocurrency, operational skills take the place of raw computational power. This means that the design process, documentation and knowledge sharing are particularly important for validator operations. This guide is a living document which details a set of best practices for running a validator service as implemented by Certus One, as well as technical background to help you design your own validator architecture. The aim of this document is to provide a baseline for validator operations, both to make it easier for new validators to get started, and to provide input to other teams. We believe that collaboration and openness strongly benefits the overall ecosystem - the more well-run validators there are, the more resilient will the network be. While this document’s focus is running blockchain validators, much of its content is applicable to operating any highly available, distributed service. While it’s hard to provide an implementation that fits all use cases, we try to provide reference implementations which implement our guidelines. This guide assumes practical Linux systems administration experience and at least basic knowledge of the blockchain you’re validating on (we recommend reading at least their whitepaper). For Cosmos, this includes both Tendermint and the Cosmos SDK. Numerous books have been written about each of the topics in this knowledge base - keep in mind that a knowledge base like ours is only ever a starting point and a guide, not an exhaustive treatment of any of the topics we’re discussing. We took a look at our bookshelves (and e-readers, and browser bookmarks) and many articles have a literature list of books and articles which we can personally recommend. The document’s source code is available on GitHub. Contributions and bug reports/feedback are greatly appreciated (feel free to use the GitHub issues for discussion as well as bug reports). ",
    "url": "/Concepts/Validator%20Operations%20Guide.html#validator-operations-guide",
    
    "relUrl": "/Concepts/Validator%20Operations%20Guide.html#validator-operations-guide"
  },"66": {
    "doc": "Validator Operations",
    "title": "Contents",
    "content": ". | Monitoring, Alerting and Instrumentation . | Symptoms-Based Alerting | What To Monitor | What To Alert | How to Monitor | How to Alert | Events | Further Reading | . | Tendermint P2P Layer . | Intro | The peer reactor | Operation Notes | The Sentry architecture | Sentry-Auto-Scaling | . | Systems Design . | Why not Kubernetes? | Network topology | Secret management | . | Security Engineering . | Single Sign On and 2FA | . | Linux Best Practices . | Configuration management | User authentication | Choice of distribution | Custom software | Docker images | Network time | DNS resolvers | . | Validator High-Availability . | Single Node Validator | Active-Standby Validator | Active-Active Validator | . | HSM for Signing . | Why use a HSM | HSM implementations | How to setup a Cosmos validator with Aiakos YubiHSM2 support | HSM hardware | . | Key Management . | Handling of the Account Key | . | Testing your tooling . | Case Study at Certus One | How to deploy | . | Building your tools and Cosmos . | Performing reproducible builds | Maintaining a mirror/fork | . | Business Continuity . | Shareholder agreements | . | . ",
    "url": "/Concepts/Validator%20Operations%20Guide.html#contents",
    
    "relUrl": "/Concepts/Validator%20Operations%20Guide.html#contents"
  },"67": {
    "doc": "Validator Operations",
    "title": "Validator Operations",
    "content": " ",
    "url": "/Concepts/Validator%20Operations%20Guide.html",
    
    "relUrl": "/Concepts/Validator%20Operations%20Guide.html"
  },"68": {
    "doc": "Values",
    "title": "Excellence¶",
    "content": "Excellence is one of our core values. Our success is a direct measure of the quality of our work. There’s no hyper-growth, just delivering great, in-depth advice and robust infrastructure. No “moving fast and break things”. There’s no . No perfectionism or pedantry, but going home knowing we did the best work we possible could. This also means: . | Reducing our workload by clever and lean designs, not by taking bad shortcuts. | Not overcommitting ourselves | . If in doubt, we take an extra ten minutes to fix up that piece of internal documentation, discuss something before we start building it, or complete an overdue refactoring. Maintaining code is much more expensive than writing it, and each minute we spend is an investment that immediately starts paying dividends. If our experience taught us anything, is that technical debt is one of the . ",
    "url": "/Concepts/Values.html#excellence",
    
    "relUrl": "/Concepts/Values.html#excellence"
  },"69": {
    "doc": "Values",
    "title": "Work-life balance",
    "content": "While early-stage companies like ours are often associated with “crunch time”, all-nighters, and 80 hours weeks, we don’t believe that these are necessary or, in fact, more productive than maintaining a healthy schedule. We still expect to pull the occasional all-nighter or experience crunch periods (which are exhausting, but also very rewarding), but not for any prolonged period of time. We prefer a sustainable pace over a series of exhausting sprints. The quality of our work is directly related to our well-being. and covering for each other if we need a rest. ",
    "url": "/Concepts/Values.html#work-life-balance",
    
    "relUrl": "/Concepts/Values.html#work-life-balance"
  },"70": {
    "doc": "Values",
    "title": "Constructive criticism",
    "content": "Being able to constructively criticize each other is one of our most important values. We want to establish devoid of personal. This is particularly important for our co-founders. ",
    "url": "/Concepts/Values.html#constructive-criticism",
    
    "relUrl": "/Concepts/Values.html#constructive-criticism"
  },"71": {
    "doc": "Values",
    "title": "Values",
    "content": " ",
    "url": "/Concepts/Values.html",
    
    "relUrl": "/Concepts/Values.html"
  },"72": {
    "doc": "Vault",
    "title": "Vault",
    "content": "https://github.com/saberistic/solana-secrets-engine . https://medium.com/hashicorp-engineering/hashicorp-vault-performance-benchmark-13d0ea7b703f . https://learn.hashicorp.com/tutorials/vault/performance-tuning?in=vault/operations . https://www.hashicorp.com/blog/building-a-vault-secure-plugin . ",
    "url": "/Tools/Vault%20fd5dd827a9de4245937760f75b9a6baa.html",
    
    "relUrl": "/Tools/Vault%20fd5dd827a9de4245937760f75b9a6baa.html"
  },"73": {
    "doc": "Home",
    "title": "Home",
    "content": "This is an in depth knowledge base on best practices for operating a validator and/or other blockchain based infrastructure company. ",
    "url": "/",
    
    "relUrl": "/"
  },"74": {
    "doc": "Consensus Layer Nodes",
    "title": "CL Nodes",
    "content": ". | Lighthouse . | Lodestar . | Nimbus . | Prysm . | Teku . | . ",
    "url": "/Nodes/cl/nodes.html#cl-nodes",
    
    "relUrl": "/Nodes/cl/nodes.html#cl-nodes"
  },"75": {
    "doc": "Consensus Layer Nodes",
    "title": "Consensus Layer Nodes",
    "content": " ",
    "url": "/Nodes/cl/nodes.html",
    
    "relUrl": "/Nodes/cl/nodes.html"
  },"76": {
    "doc": "Execution Layer Nodes",
    "title": "EL Nodes",
    "content": ". | Besu . | Erigon . | Geth . | Nethermind . | . ",
    "url": "/Nodes/el/nodes.html#el-nodes",
    
    "relUrl": "/Nodes/el/nodes.html#el-nodes"
  },"77": {
    "doc": "Execution Layer Nodes",
    "title": "Execution Layer Nodes",
    "content": " ",
    "url": "/Nodes/el/nodes.html",
    
    "relUrl": "/Nodes/el/nodes.html"
  },"78": {
    "doc": "Consensus Layer Provisioning",
    "title": "Provisioning Consensus Layer (Checkpoint Sync)",
    "content": "First, it is important to note that provisioning consensus layer via snapshots of data folder is a bad practice. Multiple nodes might end up with the same node ID, and that will bring issues during peers discovery (only one node with a certain ID could be connected to the peers). Good news, is that all CL nodes have a cross-compatible way of syncing quickly: checkpoint sync. What it does, is it takes the latest blockchain state from another node (or a file) and applies it w/o doing all the necessary checks. Only use trusted source nodes for Checkpoint sync!. | Lighthouse: https://lighthouse-book.sigmaprime.io/checkpoint-sync.html | Lodestar: (use --checkpointSyncUrl, see https://chainsafe.github.io/lodestar/reference/cli/)) | Nimbus: https://nimbus.guide/trusted-node-sync.html | Prysm: https://docs.prylabs.network/docs/prysm-usage/checkpoint-sync | Teku: https://docs.teku.consensys.net/en/latest/HowTo/Get-Started/Checkpoint-Start/ | . Your Own Checkpoint Sync . You can checkpoint-sync from any up-to-date CL node, that has beacon API enabled. samcm/checkpointz is a tool that allows you to setup your own checkpoint sync endpoint and make it public if needed. Public Checkpoint Sync Endpoints . Community-maintained list of public checkpoint sync services – use it if you don’t have your own checkpoint sync endpoints or have no up-to-date consensus layer nodes. When syncing from one of the public sources, always validate that your node is synced to the correct chain. Use this article to learn how to do that. In Prysm you can also use —-weak-subjectivity-checkpoint flag (read more here). Checkpoint Sync From A File . For most of the CL nodes, you can store the latest state of the network into a file, in SSZ format and use that instead of another node. That is useful if you don’t have any trusted node or you have to recreate the setup after it being completely lost. Most of the nodes require both the latest finalized state and the block corresponding to the finalized state. A good practice is to keep these files upgraded once every week. How to create these files, you can read here: “Sync from checkpoint files” in Nimbus Guide. The files obtained there are cross-node compatible. ",
    "url": "/Nodes/cl/provisioning.html#provisioning-consensus-layer-checkpoint-sync",
    
    "relUrl": "/Nodes/cl/provisioning.html#provisioning-consensus-layer-checkpoint-sync"
  },"79": {
    "doc": "Consensus Layer Provisioning",
    "title": "Consensus Layer Provisioning",
    "content": " ",
    "url": "/Nodes/cl/provisioning.html",
    
    "relUrl": "/Nodes/cl/provisioning.html"
  },"80": {
    "doc": "Execution Provisioing",
    "title": "Provisioning/Scaling Execution Layer",
    "content": "Execution layer node is the heavier one of the two. There is no universal way of quickly provisioning the node. The usual way is to copy some files from a datadir. It is important not to copy the full datadir because that could lead to multiple nodes having the same peer ID and having troubles connecting to the same peers. Eth1 p2p protocol devp2p forbids connecting multiple nodes with the same ID to the same peer. Only the first one will be connected, the rest will be dropped. To check the ID of your node use admin_nodeInfo RPC call, enode field. Files to copy: . | Besu - | Erigon - &lt;datadir&gt;/chaindata &amp;&amp; &lt;datadir&gt;/snapshots (also need to copy `/clique if you have it). | Geth - &lt;datadir&gt; | Nethermind - &lt;datadir&gt;/db | . ",
    "url": "/Nodes/el/provisioning.html#provisioningscaling-execution-layer",
    
    "relUrl": "/Nodes/el/provisioning.html#provisioningscaling-execution-layer"
  },"81": {
    "doc": "Execution Provisioing",
    "title": "Execution Provisioing",
    "content": " ",
    "url": "/Nodes/el/provisioning.html",
    
    "relUrl": "/Nodes/el/provisioning.html"
  }
}
